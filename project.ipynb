{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7635de20",
   "metadata": {
    "papermill": {
     "duration": 0.006643,
     "end_time": "2024-07-04T17:18:32.140337",
     "exception": false,
     "start_time": "2024-07-04T17:18:32.133694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8344204d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:18:32.154272Z",
     "iopub.status.busy": "2024-07-04T17:18:32.153930Z",
     "iopub.status.idle": "2024-07-04T17:18:45.763970Z",
     "shell.execute_reply": "2024-07-04T17:18:45.763211Z"
    },
    "papermill": {
     "duration": 13.619738,
     "end_time": "2024-07-04T17:18:45.766334",
     "exception": false,
     "start_time": "2024-07-04T17:18:32.146596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 17:18:35.744996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-04 17:18:35.745099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-04 17:18:35.873828: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from typing import TypeVar, Tuple, Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "import optuna\n",
    "\n",
    "Self = TypeVar(\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e84f1",
   "metadata": {
    "papermill": {
     "duration": 0.006096,
     "end_time": "2024-07-04T17:18:45.779130",
     "exception": false,
     "start_time": "2024-07-04T17:18:45.773034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a28b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:18:45.793354Z",
     "iopub.status.busy": "2024-07-04T17:18:45.792849Z",
     "iopub.status.idle": "2024-07-04T17:18:45.813324Z",
     "shell.execute_reply": "2024-07-04T17:18:45.812509Z"
    },
    "papermill": {
     "duration": 0.029846,
     "end_time": "2024-07-04T17:18:45.815145",
     "exception": false,
     "start_time": "2024-07-04T17:18:45.785299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_year_and_title(row):\n",
    "    \"\"\"\n",
    "    Fonction qui extrait l'année d'une chaine de caractères.\n",
    "    Cela permet de séparer l'année et le titre d'un film\n",
    "    \n",
    "    Paramètres:\n",
    "    ----------\n",
    "    row: string\n",
    "        la phrase contenant le titre et l'année de sortie\n",
    "    \n",
    "    Retours:\n",
    "    -------\n",
    "    Tuple[String, String]\n",
    "        le titre du film et son année\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\((\\d{4})\\)$', row)\n",
    "    if match:\n",
    "        year = match.group(1)\n",
    "        title = row[:match.start()].strip()\n",
    "    else:\n",
    "        year = None\n",
    "        title = row\n",
    "    return title, year\n",
    "\n",
    "\n",
    "def combine_genres(row):\n",
    "    \"\"\"\n",
    "    Fonction pour combiner les genres des deux colonnes en une chaine de caractère (sans les dupliqués)\n",
    "    \n",
    "    Paramètres:\n",
    "    ----------\n",
    "    row: dataframe pandas\n",
    "        la ligne du dataframe qui contient les deux colonnes (genre_x et genre_y)\n",
    "    \n",
    "    Retours:\n",
    "    -------\n",
    "    String\n",
    "        l'ensemble des genres séparés par des ','\n",
    "    \"\"\"\n",
    "    genrex = row['genres_x']\n",
    "    genrey = row['genres_y']\n",
    "    genres = genrex.split('|') + (genrey.split(',') if pd.notna(row['genres_y']) else [])\n",
    "    #enlever les doublons\n",
    "    unique_genres = list(set(genres))\n",
    "    #recréer une string séparée par des ','\n",
    "    return ','.join(unique_genres)\n",
    "\n",
    "\n",
    "def split_ratings(\n",
    "    ratings: np.ndarray, \n",
    "    val_size: Union[float, int], \n",
    "    test_size: Union[float, int]\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Fonction pour créer des ensembles de validation et de test à partir d'une matrice de notes\n",
    "\n",
    "    Paramètres:\n",
    "    ----------\n",
    "    ratings : np.ndarray\n",
    "        La matrice des notes (peut être clairsemée, remplie de zéros ou de valeurs manquantes).\n",
    "    val_size : float ou int\n",
    "        La taille de l'ensemble de validation.\n",
    "        Si float, la taille est exprimée en pourcentage de la taille totale du tableau des notes.\n",
    "        Si int, la taille est exprimée en nombre brut de notes dans l'ensemble de validation.\n",
    "    test_size : float ou int\n",
    "        La taille de l'ensemble de test.\n",
    "        Si float, la taille est exprimée en pourcentage de la taille totale du tableau des notes.\n",
    "        Si int, la taille est exprimée en nombre brut de notes dans l'ensemble de test.\n",
    "\n",
    "    Retours:\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        Le tuple des notes d'entraînement, de validation et de test.\n",
    "    \"\"\"\n",
    "    #Prépare les 3 matrices de résultats\n",
    "    rows, cols = np.where(ratings > 0)\n",
    "    val_ratings = np.zeros(ratings.shape)\n",
    "    test_ratings = np.zeros(ratings.shape)\n",
    "    train_ratings = ratings.copy()\n",
    "\n",
    "    total_ratings = len(rows)\n",
    "\n",
    "    if val_size < 1:  # si c'est un pourcentage\n",
    "        val_size = int(total_ratings * val_size)\n",
    "    if test_size < 1:  # si c'est un pourcentage\n",
    "        test_size = int(total_ratings * test_size)\n",
    "\n",
    "    total_sample_size = val_size + test_size\n",
    "\n",
    "    # Récupère aléatoirement les indices pour le set de validation et de test\n",
    "    sample_indices = random.sample(range(total_ratings), total_sample_size)\n",
    "    val_indices = sample_indices[:val_size]\n",
    "    test_indices = sample_indices[val_size:]\n",
    "\n",
    "    # Remplis le set de validation\n",
    "    for idx in val_indices:\n",
    "        row, col = rows[idx], cols[idx]\n",
    "        #permet de les enlever du set d'entraînement pour les séparer totalement\n",
    "        train_ratings[row, col] = 0\n",
    "        val_ratings[row, col] = ratings[row, col]\n",
    "\n",
    "    # Remplis le set de test\n",
    "    for idx in test_indices:\n",
    "        row, col = rows[idx], cols[idx]\n",
    "        #permet de les enlever du set d'entraînement pour les séparer totalement\n",
    "        train_ratings[row, col] = 0\n",
    "        test_ratings[row, col] = ratings[row, col]\n",
    "\n",
    "    return train_ratings, val_ratings, test_ratings\n",
    "\n",
    "\n",
    "def normalizeRatings(Y: np.ndarray, R: np.ndarray, axis: int = 1) -> Tuple:\n",
    "    \"\"\"\n",
    "    Prétraiter les données en soustrayant la note moyenne pour chaque film (chaque ligne).\n",
    "    Inclure uniquement les notes réelles : R(i,j)=1.\n",
    "\n",
    "    [Ynorm, Ymean] = normalizeRatings(Y, R) normalise Y pour que chaque film\n",
    "    ait une note de 0 en moyenne. Les films non notés ont alors une note moyenne (0)\n",
    "    Renvoie la note moyenne dans Ymean.\n",
    "\n",
    "    Paramètres:\n",
    "    ----------\n",
    "    Y : np.ndarray\n",
    "        Le tableau de notes à normaliser.\n",
    "    R : np.ndarray\n",
    "        Le tableau indiquant si un utilisateur a noté un film.\n",
    "    axis : int\n",
    "        L'axe numpy à utiliser pour calculer la note moyenne.\n",
    "\n",
    "    Retours:\n",
    "    -------\n",
    "    Tuple\n",
    "        Le tableau normalisé des notes et la note moyenne.\n",
    "    \"\"\"\n",
    "    Ymean = (np.sum(Y * R, axis=axis) / (np.sum(R, axis=axis) + 1e-12)).reshape(-1, 1)\n",
    "\n",
    "    if axis == 0:\n",
    "        Ynorm = Y.T - np.multiply(Ymean, R.T)\n",
    "    else:\n",
    "        Ynorm = Y - np.multiply(Ymean, R)\n",
    "\n",
    "    return (Ynorm, Ymean)\n",
    "\n",
    "\n",
    "def cofi_cost_func_v(X, W, W_features, b, Y, R,movie_features, lambda_):\n",
    "    \"\"\"\n",
    "    Renvoie le coût pour le filtrage basé sur le contenu\n",
    "    Vectorisé pour la vitesse. Utilise les opérations TensorFlow pour être compatible avec une boucle d'entraînement personnalisée.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    X: np.ndarray (num_movies,num_features)\n",
    "        Matrice des caractéristiques des items\n",
    "    W: np.ndarray (num_users,num_features)\n",
    "        Matrice des paramètres des utilisateurs\n",
    "    W_features: np.ndarray (num_movie_features, num_features)\n",
    "        Matrice de poids des features des films\n",
    "    b: np.ndarray (1, num_users)\n",
    "        Vecteur des paramètres des utilisateurs\n",
    "    Y: np.ndarray (num_movies,num_users)\n",
    "        Matrice des notes des utilisateurs pour les films\n",
    "    R: np.ndarray (num_movies,num_users)\n",
    "        Matrice où R(i, j) = 1 si le i-ème film a été noté par le j-ème utilisateur\n",
    "    movie_features: np.ndarray\n",
    "        Matrice des features des films\n",
    "    lambda_: float\n",
    "        Paramètre de régularisation\n",
    "\n",
    "    Retours:\n",
    "    -------\n",
    "    float\n",
    "        La valeur du coût étant donné les paramètres.\n",
    "    \"\"\"\n",
    "    #Calcule le biais apportés par les caractéristiques (features) des films\n",
    "    movie_bias = tf.matmul(movie_features, W_features)\n",
    "    \n",
    "    # On ajoute ce biais aux caractéristiques déjà connues (X) pour prendre en compte l'influence\n",
    "    # des features sur les notes des utilisateurs (= ajouts de nouvelles caractéristiques) \n",
    "    j = (tf.linalg.matmul(X + movie_bias, tf.transpose(W)) + b - Y) * R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_ / 2) * (\n",
    "        tf.reduce_sum(X**2) + tf.reduce_sum(W**2) + tf.reduce_sum(W_features**2)\n",
    "    )\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7477e9",
   "metadata": {
    "papermill": {
     "duration": 0.006047,
     "end_time": "2024-07-04T17:18:45.827330",
     "exception": false,
     "start_time": "2024-07-04T17:18:45.821283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chargement et traitements des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826fa07",
   "metadata": {
    "papermill": {
     "duration": 0.005969,
     "end_time": "2024-07-04T17:18:45.839549",
     "exception": false,
     "start_time": "2024-07-04T17:18:45.833580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Chargement de movieLens (movies et ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc19116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:18:45.852994Z",
     "iopub.status.busy": "2024-07-04T17:18:45.852729Z",
     "iopub.status.idle": "2024-07-04T17:18:54.215878Z",
     "shell.execute_reply": "2024-07-04T17:18:54.215032Z"
    },
    "papermill": {
     "duration": 8.372478,
     "end_time": "2024-07-04T17:18:54.218209",
     "exception": false,
     "start_time": "2024-07-04T17:18:45.845731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Movies\n",
    "df_movies1 = pd.read_csv(\n",
    "        \"./data/movielens_complete/ml-1m/movies.dat\",\n",
    "        sep=\"::\",\n",
    "        encoding='ISO-8859-1',\n",
    "        engine='python',\n",
    "        header=None\n",
    "    )\n",
    "\n",
    "df_movies1.columns = [\"movieId\", \"title\", \"genres\"]\n",
    "\n",
    "#Séparation des titres en titre et années pour pouvoir le lier à l'autre dataset\n",
    "df_movies1['title'], df_movies1['year'] = zip(*df_movies1['title'].map(extract_year_and_title))\n",
    "\n",
    "\n",
    "#Ratings\n",
    "df_ratings1 = pd.read_csv(\n",
    "        \"./data/movielens_complete/ml-1m/ratings.dat\",\n",
    "        sep=\"::\",\n",
    "        encoding='ISO-8859-1',\n",
    "        engine='python',\n",
    "        header=None\n",
    "    )\n",
    "\n",
    "df_ratings1.columns = [\"userId\",\"movieId\",\"Rating\",\"timestamp\"]\n",
    "\n",
    "\n",
    "#matrice d'interaction utilisateur-films\n",
    "df_matrix = df_ratings1.pivot(index=\"movieId\", columns=\"userId\", values=\"Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49565e",
   "metadata": {
    "papermill": {
     "duration": 0.006057,
     "end_time": "2024-07-04T17:18:54.230800",
     "exception": false,
     "start_time": "2024-07-04T17:18:54.224743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Chargement de IMbd (titleBasics, title_crew et ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b9952e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:18:54.244318Z",
     "iopub.status.busy": "2024-07-04T17:18:54.244030Z",
     "iopub.status.idle": "2024-07-04T17:19:47.026449Z",
     "shell.execute_reply": "2024-07-04T17:19:47.025679Z"
    },
    "papermill": {
     "duration": 52.791859,
     "end_time": "2024-07-04T17:19:47.028848",
     "exception": false,
     "start_time": "2024-07-04T17:18:54.236989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/3002934010.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_movies2 = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "#Chargement de titleBasics\n",
    "df_movies2 = pd.read_csv(\n",
    "        \"./data/IMDb/title.basics.tsv\",\n",
    "        sep='\\t'\n",
    "    )\n",
    "\n",
    "#Surpression de tout ce qui n'est pas un movie pour pouvoir le combiner plus tard\n",
    "df_movies2.drop(df_movies2[df_movies2['titleType'] != 'movie'].index, inplace=True)\n",
    "\n",
    "\n",
    "#Chargement de titleCrew\n",
    "df_crew = pd.read_csv(\n",
    "        \"./data/IMDb/title.crew.tsv\",\n",
    "        sep='\\t'\n",
    "    )\n",
    "\n",
    "df_crew.drop(columns=['writers'], inplace=True)\n",
    "\n",
    "#chargement de ratings\n",
    "df_ratings2 = pd.read_csv(\n",
    "        \"./data/IMDb/title.ratings.tsv\",\n",
    "        sep='\\t'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b18667",
   "metadata": {
    "papermill": {
     "duration": 0.006175,
     "end_time": "2024-07-04T17:19:47.041904",
     "exception": false,
     "start_time": "2024-07-04T17:19:47.035729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Merge des deux datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e8c1a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:19:47.055682Z",
     "iopub.status.busy": "2024-07-04T17:19:47.055372Z",
     "iopub.status.idle": "2024-07-04T17:19:57.471098Z",
     "shell.execute_reply": "2024-07-04T17:19:57.470099Z"
    },
    "papermill": {
     "duration": 10.424976,
     "end_time": "2024-07-04T17:19:57.473216",
     "exception": false,
     "start_time": "2024-07-04T17:19:47.048240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/970431456.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_movies['isAdult'] = df_movies['isAdult'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "#merge des datasets movies pour obtenir plus de metadata\n",
    "df_movies = pd.merge(df_movies1, df_movies2, left_on=['title', 'year'], right_on=['primaryTitle', 'startYear'], how='left')\n",
    "df_movies.drop_duplicates(subset='movieId', keep='first', inplace=True)\n",
    " \n",
    "#merge des movies et de ratings pour avoir les notes moyennes en metadata\n",
    "df_movies = pd.merge(df_movies, df_ratings2, on='tconst', how='left')\n",
    "\n",
    "#merge de movies et de crew pour avoir les directors en metadata\n",
    "df_movies = pd.merge(df_movies, df_crew, on='tconst', how='left')\n",
    "\n",
    "#nettoyage du df_movies\n",
    "df_movies['genres'] = df_movies.apply(combine_genres, axis=1)\n",
    "df_movies['directors'] = df_movies['directors'].fillna('')\n",
    "df_movies['isAdult'] = df_movies['isAdult'].fillna(0)\n",
    "#pour ne pas mettre 0 et influencer les choix trop négativement pour ces films, on remplace les nan par la moyenne des averageRating\n",
    "df_movies['averageRating'] = df_movies['averageRating'].fillna(df_movies['averageRating'].mean())\n",
    "df_movies['averageRating'] = df_movies['averageRating'] / 2\n",
    "df_movies.drop(columns=['tconst', 'titleType', 'primaryTitle', 'originalTitle', 'startYear', 'endYear', 'runtimeMinutes', 'genres_x', 'genres_y'], inplace=True)\n",
    "\n",
    "# Rajout des films qui n'ont jamais été notés pour permettre l'utilisation des features plus tard\n",
    "movie_ids_in_movies = set(df_movies['movieId'])\n",
    "movie_ids_in_ratings = set(df_matrix.index)\n",
    "missing_movie_ids = movie_ids_in_movies - movie_ids_in_ratings\n",
    "new_entries = pd.DataFrame(np.nan, index=list(missing_movie_ids), columns=df_matrix.columns)\n",
    "df_matrix = pd.concat([df_matrix, new_entries], ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce7086",
   "metadata": {
    "papermill": {
     "duration": 0.006505,
     "end_time": "2024-07-04T17:19:57.486373",
     "exception": false,
     "start_time": "2024-07-04T17:19:57.479868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Création des np.array pour le collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0bc6bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:19:57.500281Z",
     "iopub.status.busy": "2024-07-04T17:19:57.499982Z",
     "iopub.status.idle": "2024-07-04T17:19:57.655497Z",
     "shell.execute_reply": "2024-07-04T17:19:57.654702Z"
    },
    "papermill": {
     "duration": 0.165037,
     "end_time": "2024-07-04T17:19:57.657785",
     "exception": false,
     "start_time": "2024-07-04T17:19:57.492748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "R = df_matrix.notna().astype(int).to_numpy()\n",
    "df_matrix = df_matrix.fillna(0)\n",
    "Y = df_matrix.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c5991",
   "metadata": {
    "papermill": {
     "duration": 0.006284,
     "end_time": "2024-07-04T17:19:57.670731",
     "exception": false,
     "start_time": "2024-07-04T17:19:57.664447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features_engineering\n",
    "\n",
    "- encodage des genres et des directors en matrice binaire pour être utilisé comme features\n",
    "- utilisation de isAdult et de averageRating (remis sur 5) comme features\n",
    "- scaling de la matrice de features pour donner le même poids à chacune d'entre elles et pour lui permettre d'être utilisée plus tard dans l'entraînement\n",
    "\n",
    "Genres et directors sont choisis car les gens ont souvent des préférences pour des genres ou des préférences pour certains directeurs de films.\n",
    "\n",
    "isAdult est choisi car certaines personnes peuvent préférer des films considérés comme pour les adultes plutôt que des films plus enfantins.\n",
    "\n",
    "averageRating est choisi car c'est une donnée que les gens peuvent regarder pour choisir un film (si un film est bien noté en moyenne, on aura tendance à le préférer). Cela peut également aider si un film n'est pas beaucoup noté ou n'est pas du tout noté par les utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66febd74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:19:57.685074Z",
     "iopub.status.busy": "2024-07-04T17:19:57.684369Z",
     "iopub.status.idle": "2024-07-04T17:19:58.650208Z",
     "shell.execute_reply": "2024-07-04T17:19:58.649387Z"
    },
    "papermill": {
     "duration": 0.975415,
     "end_time": "2024-07-04T17:19:58.652554",
     "exception": false,
     "start_time": "2024-07-04T17:19:57.677139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transformation des strings en liste pour être utilisé par MultiLabelBinarizer\n",
    "df_movies['genres'] = df_movies['genres'].apply(lambda x: x.split(','))\n",
    "df_movies['directors'] = df_movies['directors'].apply(lambda x: x.split(','))\n",
    "\n",
    "# Transformation en matrice binaire\n",
    "genres_mlb = MultiLabelBinarizer()\n",
    "genres_encoded = genres_mlb.fit_transform(df_movies['genres'])\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=genres_mlb.classes_)\n",
    "\n",
    "directors_mlb = MultiLabelBinarizer()\n",
    "directors_encoded = directors_mlb.fit_transform(df_movies['directors'])\n",
    "directors_df = pd.DataFrame(directors_encoded, columns=directors_mlb.classes_)\n",
    "\n",
    "features = pd.concat([genres_df,directors_df, df_movies[['isAdult', 'averageRating']]], axis=1)\n",
    "\n",
    "# Scaling de la matrice de features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "movie_features = tf.constant(features_scaled, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "641b5669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:19:58.667097Z",
     "iopub.status.busy": "2024-07-04T17:19:58.666781Z",
     "iopub.status.idle": "2024-07-04T17:19:59.085283Z",
     "shell.execute_reply": "2024-07-04T17:19:59.084493Z"
    },
    "papermill": {
     "duration": 0.428184,
     "end_time": "2024-07-04T17:19:59.087597",
     "exception": false,
     "start_time": "2024-07-04T17:19:58.659413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Données utiles\n",
    "num_movies, num_users = Y.shape\n",
    "num_movie_features = movie_features.shape[1]\n",
    "movieList = df_movies[\"title\"].to_list()\n",
    "\n",
    "#Séparation en train, val et test\n",
    "Y_train, Y_val, Y_test = split_ratings(Y, val_size=627, test_size=626)\n",
    "Ynorm, Ymean = normalizeRatings(Y_train, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f065949",
   "metadata": {
    "papermill": {
     "duration": 0.006276,
     "end_time": "2024-07-04T17:19:59.100598",
     "exception": false,
     "start_time": "2024-07-04T17:19:59.094322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modèle de recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86c1d6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:19:59.114755Z",
     "iopub.status.busy": "2024-07-04T17:19:59.114438Z",
     "iopub.status.idle": "2024-07-04T17:19:59.141059Z",
     "shell.execute_reply": "2024-07-04T17:19:59.140215Z"
    },
    "papermill": {
     "duration": 0.036155,
     "end_time": "2024-07-04T17:19:59.143006",
     "exception": false,
     "start_time": "2024-07-04T17:19:59.106851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MovieRecommender:\n",
    "\n",
    "    def __init__(self, num_users, num_movies, num_features, num_movie_features, movieFeatures):\n",
    "        \"\"\"\n",
    "        Initialisation de notre système de recommendation\n",
    "\n",
    "        Paramètres:\n",
    "        -----------\n",
    "        num_user: int\n",
    "            nombre d'utilisateurs dans notre système\n",
    "        num_movies: int\n",
    "            nombre de films\n",
    "        num_features: int\n",
    "            nombre de features du système\n",
    "        num_movie_features: int\n",
    "            nombre de caractèristiques (features type genre, directors etc) des films\n",
    "        movieFeatures: tf.tensor\n",
    "            tensor contenant les caractéristiques (features type genre, directors etc) pour chaque film\n",
    "        \"\"\"\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.num_features = num_features\n",
    "        self.num_movie_features = num_movie_features\n",
    "        self.movieFeatures = movieFeatures\n",
    "        \n",
    "        tf.random.set_seed(1234)\n",
    "        \n",
    "        self.X = tf.Variable(tf.random.normal((self.num_movies, self.num_features), dtype=tf.float64), name=\"X\")\n",
    "        self.W = tf.Variable(tf.random.normal((self.num_users, self.num_features), dtype=tf.float64), name=\"W\")\n",
    "        self.b = tf.Variable(tf.random.normal((1, self.num_users), dtype=tf.float64), name=\"b\")\n",
    "        self.W_features = tf.Variable(tf.random.normal((self.num_movie_features, self.num_features), dtype=tf.float64), name=\"W_features\")\n",
    "        \n",
    "        self.mean = None\n",
    "        \n",
    "        \n",
    "    def fit(self, Y, mean, r_mask, iterations, lambda_, learning_r):\n",
    "        \"\"\"\n",
    "        Fonction qui entraîne notre système de recommendation\n",
    "        \n",
    "        Paramètres:\n",
    "        -----------\n",
    "        Y: np.ndarray\n",
    "            Le tableau de notes\n",
    "        mean: np.array\n",
    "            Le tableau avec les notes moyennes (pour calculer plus tard les résultats)\n",
    "        r_mask: np.ndarray\n",
    "            Le tableau indiquant si un utilisateur a noté un film.\n",
    "        iterations: int\n",
    "            Le nombre d'itérations à réaliser pour l'entrainement du modèle\n",
    "        lambda_: float\n",
    "            Le paramètre de régularisation\n",
    "        learning_r: float\n",
    "            Le learning_rate pour l'optimizer\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_r)\n",
    "        for iter in range(iterations):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Calcule le coût\n",
    "                cost_value = cofi_cost_func_v(self.X, self.W, self.W_features, self.b, Y, r_mask, self.movieFeatures, lambda_)\n",
    "\n",
    "            grads = tape.gradient(cost_value, [self.X, self.W, self.W_features, self.b])\n",
    "\n",
    "            # Effectue une étape de descente de gradient en mettant à jour la valeur des variables pour minimiser la perte.\n",
    "            optimizer.apply_gradients(zip(grads, [self.X, self.W, self.W_features, self.b]))\n",
    "\n",
    "            if iter % 20 == 0:\n",
    "                print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")\n",
    "    \n",
    "    \n",
    "    def getResults(self):\n",
    "        \"\"\"\n",
    "        Fonction qui récupère la matrice de scores\n",
    "        \n",
    "        Retours:\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Notes des utilisateurs pour chaque film\n",
    "        \"\"\"\n",
    "        movie_bias = tf.matmul(self.movieFeatures, self.W_features)\n",
    "        p = np.matmul(self.X.numpy() + movie_bias.numpy(), np.transpose(self.W.numpy())) + self.b.numpy()\n",
    "\n",
    "        # ajout de la moyenne pour obtenir les bonnes valeurs\n",
    "        pm = p + self.mean\n",
    "        \n",
    "        # bloquer les valeurs entre 0 et 5 pour éviter des valeurs trop grandes (possible à cause de l'ajout de la moyenne)\n",
    "        pm = np.clip(pm, 0, 5)\n",
    "        \n",
    "        return pm\n",
    "    \n",
    "\n",
    "    def getError(self, Yval, movieList, printExemples=False):\n",
    "        \"\"\"\n",
    "        Fonction qui récupère l'erreur moyenne des prédictions (métrique pour évaluer le modèle)\n",
    "        \n",
    "        Paramètres:\n",
    "        ----------\n",
    "        Yval: np.ndarray\n",
    "            Le tableau des notes\n",
    "        movieList: List\n",
    "            La liste contenant les titres de tous les films\n",
    "        printExemples: bool\n",
    "            Variable qui permet de print certaines prédictions et leur véritable valeur\n",
    "        \n",
    "        Retours:\n",
    "        -------\n",
    "        float\n",
    "            l'erreur abolue moyenne de notre modèle\n",
    "        \"\"\"\n",
    "        pm = self.getResults()\n",
    "\n",
    "        # Récupération des notes de départ\n",
    "        non_zero_indices = np.nonzero(Yval)\n",
    "        rows, cols = non_zero_indices\n",
    "        \n",
    "        if(printExemples):\n",
    "            for k in range (5):\n",
    "                my_ratings = Yval[:,cols[k]]\n",
    "                my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "                my_predictions = pm[:, k]\n",
    "\n",
    "                print(\"\\n\\nOriginal vs Predicted ratings for\",(k + 1), \"\\n\")\n",
    "                for i in range(len(my_ratings)):\n",
    "                    if my_ratings[i] > 0:\n",
    "                        print(\n",
    "                            f\"Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}\"\n",
    "                        )\n",
    "\n",
    "        predicted_ratings = pm[rows, cols]\n",
    "        real_ratings = Yval[rows, cols]\n",
    "\n",
    "        mae = np.mean(np.abs(predicted_ratings - real_ratings))\n",
    "        \n",
    "        return mae\n",
    "        \n",
    "\n",
    "    def getCoupleRatings(self, user_id1, user_id2):\n",
    "        \"\"\"\n",
    "        Fonction qui permet de récupérer les notes données par un couple de personnes\n",
    "        \n",
    "        Paramètres:\n",
    "        -----------\n",
    "        user_id1: int\n",
    "            Le premier utilisateur de notre couple\n",
    "        user_id2: int\n",
    "            Le deuxième utilisateur de notre couple\n",
    "        \n",
    "        Retours:\n",
    "        --------\n",
    "        np.array\n",
    "            L'array contenant la note donnée par notre couple pour chaque film\n",
    "        \"\"\"\n",
    "        pm = self.getResults()\n",
    "        \n",
    "        user_ratings1 = pm[:, user_id1-1]\n",
    "        user_ratings2 = pm[:, user_id2-1]\n",
    "        \n",
    "        # La note d'un couple pour un film correspond à la moyenne de leurs notes respectives\n",
    "        couple_ratings = (user_ratings1 + user_ratings2) / 2\n",
    "\n",
    "        return couple_ratings\n",
    "    \n",
    "\n",
    "    def getMovieRecommendation(self, user_id1, user_id2, movies, R):\n",
    "        \"\"\"\n",
    "        Fonction qui récupère le meilleur film pour un couple d'utilisateurs\n",
    "        \n",
    "        Paramètres:\n",
    "        -----------\n",
    "        user_id1: int\n",
    "            Le premier utilisateur de notre couple\n",
    "        user_id2: int\n",
    "            Le deuxième utilisateur de notre couple\n",
    "        movies: pd.dataframe\n",
    "            Le dataframe contenant tous les films, leurs caractéristiques etc\n",
    "        R: np.ndarray\n",
    "            Le tableau indiquant si un utilisateur a noté un film.\n",
    "            \n",
    "        Retours:\n",
    "        --------\n",
    "        object:\n",
    "            object contenant l'id, le titre et le score du film choisi pour ce couple\n",
    "        \"\"\"\n",
    "        couple_ratings = self.getCoupleRatings(user_id1, user_id2)\n",
    "        \n",
    "        # Récupère les films vu par chaque utilisateur\n",
    "        movies_seen1 = R[:, user_id1-1]\n",
    "        movies_seen2 = R[:, user_id2-1]\n",
    "\n",
    "        couple_scores = []\n",
    "        fallback_scores = []\n",
    "\n",
    "        # Calcule le couple score pour chaque film (la note donnée avec parfois un bonus)\n",
    "        # Elimine les films vu par les 2 utilisateurs\n",
    "        for i in range(len(couple_ratings)):\n",
    "            avg_rating = couple_ratings[i]\n",
    "\n",
    "            if movies_seen1[i] and movies_seen2[i]:\n",
    "                # On garde sous la main ceux notés par les deux au cas où il n'y a aucun nouveau film\n",
    "                fallback_scores.append((i, avg_rating))\n",
    "                continue\n",
    "            elif movies_seen1[i] or movies_seen2[i]:\n",
    "                couple_score = avg_rating\n",
    "            else:\n",
    "                # Les films vu par aucun des deux ont un bonus pour les prioritiser\n",
    "                couple_score = avg_rating + 1\n",
    "\n",
    "            couple_scores.append((i, couple_score))\n",
    "\n",
    "        # Choisi le film avec le meilleur couple_score\n",
    "        if not couple_scores:\n",
    "            best_movie = max(fallback_scores, key=lambda x: x[1])\n",
    "        else:\n",
    "            best_movie = max(couple_scores, key=lambda x: x[1])\n",
    "\n",
    "        best_movie_id = best_movie[0]\n",
    "        best_movie_score = best_movie[1]\n",
    "        best_movie_title = movies.iloc[best_movie_id]['title']\n",
    "\n",
    "        return {\n",
    "            'movie_id': best_movie_id + 1,\n",
    "            'title': best_movie_title,\n",
    "            'couple_score': best_movie_score\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f9ec4",
   "metadata": {
    "papermill": {
     "duration": 0.006061,
     "end_time": "2024-07-04T17:19:59.155406",
     "exception": false,
     "start_time": "2024-07-04T17:19:59.149345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utilisation du modèle avec Optuna pour trouver les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72e0b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:19:59.169320Z",
     "iopub.status.busy": "2024-07-04T17:19:59.169053Z",
     "iopub.status.idle": "2024-07-04T18:40:06.024987Z",
     "shell.execute_reply": "2024-07-04T18:40:06.024226Z"
    },
    "papermill": {
     "duration": 4806.865186,
     "end_time": "2024-07-04T18:40:06.026992",
     "exception": false,
     "start_time": "2024-07-04T17:19:59.161806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:19:59,173] A new study created in memory with name: no-name-039ecfd0-575b-4449-9c90-9263b792975c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 170590508737.1\n",
      "Training loss at iteration 20: 17007090125.5\n",
      "Training loss at iteration 40: 3859483561.7\n",
      "Training loss at iteration 60: 1498740730.9\n",
      "Training loss at iteration 80: 795819623.3\n",
      "Training loss at iteration 100: 497459667.1\n",
      "Training loss at iteration 120: 339847149.2\n",
      "Training loss at iteration 140: 245966211.3\n",
      "Training loss at iteration 160: 185777215.7\n",
      "Training loss at iteration 180: 145113989.0\n",
      "Training loss at iteration 200: 116497886.5\n",
      "Training loss at iteration 220: 95679225.1\n",
      "Training loss at iteration 240: 80107300.3\n",
      "Training loss at iteration 260: 68182408.1\n",
      "Training loss at iteration 280: 58863756.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:22:20,132] Trial 0 finished with value: 2.1014375629077726 and parameters: {'num_features': 222, 'lambda': 6.159572328019419, 'learning_rate': 0.0235000042878769, 'iterations': 291}. Best is trial 0 with value: 2.1014375629077726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 167799048826.5\n",
      "Training loss at iteration 20: 120763488595.9\n",
      "Training loss at iteration 40: 88561429476.5\n",
      "Training loss at iteration 60: 66447980874.1\n",
      "Training loss at iteration 80: 50871436959.6\n",
      "Training loss at iteration 100: 39598433502.6\n",
      "Training loss at iteration 120: 31254281107.3\n",
      "Training loss at iteration 140: 24966304338.2\n",
      "Training loss at iteration 160: 20158556456.3\n",
      "Training loss at iteration 180: 16437812836.0\n",
      "Training loss at iteration 200: 13528076649.2\n",
      "Training loss at iteration 220: 11231268923.8\n",
      "Training loss at iteration 240: 9402665057.2\n",
      "Training loss at iteration 260: 7934993439.1\n",
      "Training loss at iteration 280: 6747817418.9\n",
      "Training loss at iteration 300: 5780249477.4\n",
      "Training loss at iteration 320: 4985832806.9\n",
      "Training loss at iteration 340: 4328874229.9\n",
      "Training loss at iteration 360: 3781775420.5\n",
      "Training loss at iteration 380: 3323067123.7\n",
      "Training loss at iteration 400: 2935947982.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:25:38,073] Trial 1 finished with value: 2.4545568762392636 and parameters: {'num_features': 219, 'lambda': 7.124984215555025, 'learning_rate': 0.003074012430220078, 'iterations': 409}. Best is trial 0 with value: 2.1014375629077726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 170593249233.5\n",
      "Training loss at iteration 20: 70776104035.6\n",
      "Training loss at iteration 40: 32921446058.8\n",
      "Training loss at iteration 60: 17459148025.4\n",
      "Training loss at iteration 80: 10271176089.6\n",
      "Training loss at iteration 100: 6524342529.9\n",
      "Training loss at iteration 120: 4398327009.2\n",
      "Training loss at iteration 140: 3110906930.9\n",
      "Training loss at iteration 160: 2288733741.7\n",
      "Training loss at iteration 180: 1739556420.4\n",
      "Training loss at iteration 200: 1358401392.6\n",
      "Training loss at iteration 220: 1085058630.7\n",
      "Training loss at iteration 240: 883466306.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:27:40,775] Trial 2 finished with value: 2.289932889237065 and parameters: {'num_features': 222, 'lambda': 8.316288078575537, 'learning_rate': 0.008315766180788315, 'iterations': 253}. Best is trial 0 with value: 2.1014375629077726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 181672238312.0\n",
      "Training loss at iteration 20: 28966539818.9\n",
      "Training loss at iteration 40: 7606004750.1\n",
      "Training loss at iteration 60: 3072301767.9\n",
      "Training loss at iteration 80: 1620327234.1\n",
      "Training loss at iteration 100: 993468169.5\n",
      "Training loss at iteration 120: 666607558.1\n",
      "Training loss at iteration 140: 475481587.2\n",
      "Training loss at iteration 160: 354923405.4\n",
      "Training loss at iteration 180: 274538833.2\n",
      "Training loss at iteration 200: 218568261.7\n",
      "Training loss at iteration 220: 178206203.6\n",
      "Training loss at iteration 240: 148241733.8\n",
      "Training loss at iteration 260: 125444418.6\n",
      "Training loss at iteration 280: 107732569.9\n",
      "Training loss at iteration 300: 93719980.5\n",
      "Training loss at iteration 320: 82457060.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:30:20,560] Trial 3 finished with value: 2.248358569475689 and parameters: {'num_features': 237, 'lambda': 9.905877425748558, 'learning_rate': 0.01770274942839035, 'iterations': 330}. Best is trial 0 with value: 2.1014375629077726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 86079909469.0\n",
      "Training loss at iteration 20: 1448034816.7\n",
      "Training loss at iteration 40: 216247253.1\n",
      "Training loss at iteration 60: 58136860.6\n",
      "Training loss at iteration 80: 27690311.7\n",
      "Training loss at iteration 100: 18254783.3\n",
      "Training loss at iteration 120: 13784141.1\n",
      "Training loss at iteration 140: 11102659.6\n",
      "Training loss at iteration 160: 9310226.4\n",
      "Training loss at iteration 180: 8039011.4\n",
      "Training loss at iteration 200: 7100178.0\n",
      "Training loss at iteration 220: 6384568.2\n",
      "Training loss at iteration 240: 5824713.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:32:26,265] Trial 4 finished with value: 1.634156625544445 and parameters: {'num_features': 112, 'lambda': 6.7476778473390615, 'learning_rate': 0.07625562054555675, 'iterations': 258}. Best is trial 4 with value: 1.634156625544445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 171569941277.7\n",
      "Training loss at iteration 20: 132007557746.1\n",
      "Training loss at iteration 40: 102843081187.0\n",
      "Training loss at iteration 60: 81358728413.0\n",
      "Training loss at iteration 80: 65248649364.6\n",
      "Training loss at iteration 100: 52932759659.0\n",
      "Training loss at iteration 120: 43361759552.6\n",
      "Training loss at iteration 140: 35823655905.7\n",
      "Training loss at iteration 160: 29820634701.9\n",
      "Training loss at iteration 180: 24995274154.6\n",
      "Training loss at iteration 200: 21085241887.8\n",
      "Training loss at iteration 220: 17894430034.5\n",
      "Training loss at iteration 240: 15273953200.1\n",
      "Training loss at iteration 260: 13109293088.2\n",
      "Training loss at iteration 280: 11311393556.5\n",
      "Training loss at iteration 300: 9810358916.2\n",
      "Training loss at iteration 320: 8550905701.6\n",
      "Training loss at iteration 340: 7489020298.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:35:11,878] Trial 5 finished with value: 2.4471562802081186 and parameters: {'num_features': 225, 'lambda': 1.041011353009639, 'learning_rate': 0.002425184529574065, 'iterations': 341}. Best is trial 4 with value: 1.634156625544445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 126451015317.1\n",
      "Training loss at iteration 20: 105494743074.9\n",
      "Training loss at iteration 40: 88632847430.8\n",
      "Training loss at iteration 60: 75122406251.3\n",
      "Training loss at iteration 80: 64181785611.3\n",
      "Training loss at iteration 100: 55211420649.0\n",
      "Training loss at iteration 120: 47776928494.5\n",
      "Training loss at iteration 140: 41559644823.8\n",
      "Training loss at iteration 160: 36320348556.4\n",
      "Training loss at iteration 180: 31875814095.9\n",
      "Training loss at iteration 200: 28083410138.3\n",
      "Training loss at iteration 220: 24830605910.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:37:00,570] Trial 6 finished with value: 2.5571477748610327 and parameters: {'num_features': 165, 'lambda': 5.637372622984485, 'learning_rate': 0.0018076331634837117, 'iterations': 223}. Best is trial 4 with value: 1.634156625544445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 186844902903.4\n",
      "Training loss at iteration 20: 22671543310.2\n",
      "Training loss at iteration 40: 5389060230.7\n",
      "Training loss at iteration 60: 2111734219.9\n",
      "Training loss at iteration 80: 1111784284.1\n",
      "Training loss at iteration 100: 686684242.0\n",
      "Training loss at iteration 120: 464348782.6\n",
      "Training loss at iteration 140: 333373935.0\n",
      "Training loss at iteration 160: 250175558.1\n",
      "Training loss at iteration 180: 194384456.2\n",
      "Training loss at iteration 200: 155362376.8\n",
      "Training loss at iteration 220: 127120643.5\n",
      "Training loss at iteration 240: 106092391.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:39:02,830] Trial 7 finished with value: 2.210218603842386 and parameters: {'num_features': 243, 'lambda': 7.75915581264468, 'learning_rate': 0.020526522003130362, 'iterations': 251}. Best is trial 4 with value: 1.634156625544445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 148896258793.6\n",
      "Training loss at iteration 20: 41464090922.9\n",
      "Training loss at iteration 40: 14718015569.3\n",
      "Training loss at iteration 60: 6742635449.9\n",
      "Training loss at iteration 80: 3692028560.1\n",
      "Training loss at iteration 100: 2271240034.0\n",
      "Training loss at iteration 120: 1512554163.0\n",
      "Training loss at iteration 140: 1067013138.8\n",
      "Training loss at iteration 160: 786478391.8\n",
      "Training loss at iteration 180: 600108310.4\n",
      "Training loss at iteration 200: 470895395.6\n",
      "Training loss at iteration 220: 378135960.2\n",
      "Training loss at iteration 240: 309590384.5\n",
      "Training loss at iteration 260: 257684985.9\n",
      "Training loss at iteration 280: 217549818.0\n",
      "Training loss at iteration 300: 185949326.8\n",
      "Training loss at iteration 320: 160672266.7\n",
      "Training loss at iteration 340: 140169770.1\n",
      "Training loss at iteration 360: 123333179.9\n",
      "Training loss at iteration 380: 109353531.7\n",
      "Training loss at iteration 400: 97630314.3\n",
      "Training loss at iteration 420: 87710825.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:42:35,108] Trial 8 finished with value: 2.150699612154871 and parameters: {'num_features': 194, 'lambda': 5.180183996197331, 'learning_rate': 0.012778839399395942, 'iterations': 438}. Best is trial 4 with value: 1.634156625544445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 163467117228.2\n",
      "Training loss at iteration 20: 48367917664.0\n",
      "Training loss at iteration 40: 17780602496.7\n",
      "Training loss at iteration 60: 8254585638.4\n",
      "Training loss at iteration 80: 4533255824.9\n",
      "Training loss at iteration 100: 2785759742.9\n",
      "Training loss at iteration 120: 1850948822.0\n",
      "Training loss at iteration 140: 1302484557.6\n",
      "Training loss at iteration 160: 957802419.6\n",
      "Training loss at iteration 180: 729279417.4\n",
      "Training loss at iteration 200: 571126321.2\n",
      "Training loss at iteration 220: 457764911.3\n",
      "Training loss at iteration 240: 374105264.1\n",
      "Training loss at iteration 260: 310828938.8\n",
      "Training loss at iteration 280: 261954585.3\n",
      "Training loss at iteration 300: 223513770.7\n",
      "Training loss at iteration 320: 192797306.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:45:16,279] Trial 9 finished with value: 2.334143097900038 and parameters: {'num_features': 213, 'lambda': 4.9087528784663625, 'learning_rate': 0.011807030673668239, 'iterations': 333}. Best is trial 4 with value: 1.634156625544445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 57013718090.1\n",
      "Training loss at iteration 20: 749098513.9\n",
      "Training loss at iteration 40: 104401714.4\n",
      "Training loss at iteration 60: 24581769.1\n",
      "Training loss at iteration 80: 10430427.5\n",
      "Training loss at iteration 100: 6457923.7\n",
      "Training loss at iteration 120: 4715927.4\n",
      "Training loss at iteration 140: 3715971.7\n",
      "Training loss at iteration 160: 3065598.1\n",
      "Training loss at iteration 180: 2614354.8\n",
      "Training loss at iteration 200: 2287722.3\n",
      "Training loss at iteration 220: 2043501.3\n",
      "Training loss at iteration 240: 1855976.1\n",
      "Training loss at iteration 260: 1708695.5\n",
      "Training loss at iteration 280: 1590736.8\n",
      "Training loss at iteration 300: 1494623.4\n",
      "Training loss at iteration 320: 1415382.8\n",
      "Training loss at iteration 340: 1348425.9\n",
      "Training loss at iteration 360: 1291763.8\n",
      "Training loss at iteration 380: 1243116.0\n",
      "Training loss at iteration 400: 1200907.1\n",
      "Training loss at iteration 420: 1163937.3\n",
      "Training loss at iteration 440: 1131275.5\n",
      "Training loss at iteration 460: 1102189.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:49:08,107] Trial 10 finished with value: 1.0973299889007304 and parameters: {'num_features': 75, 'lambda': 2.2034641068278304, 'learning_rate': 0.09151981871650455, 'iterations': 479}. Best is trial 10 with value: 1.0973299889007304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 59939128176.5\n",
      "Training loss at iteration 20: 901027182.8\n",
      "Training loss at iteration 40: 130319863.2\n",
      "Training loss at iteration 60: 32399719.6\n",
      "Training loss at iteration 80: 14210465.0\n",
      "Training loss at iteration 100: 8804324.4\n",
      "Training loss at iteration 120: 6339587.3\n",
      "Training loss at iteration 140: 4901039.1\n",
      "Training loss at iteration 160: 3960703.0\n",
      "Training loss at iteration 180: 3307969.6\n",
      "Training loss at iteration 200: 2836234.5\n",
      "Training loss at iteration 220: 2484535.4\n",
      "Training loss at iteration 240: 2215540.3\n",
      "Training loss at iteration 260: 2005297.1\n",
      "Training loss at iteration 280: 1837871.3\n",
      "Training loss at iteration 300: 1702340.2\n",
      "Training loss at iteration 320: 1591023.0\n",
      "Training loss at iteration 340: 1498408.5\n",
      "Training loss at iteration 360: 1420416.3\n",
      "Training loss at iteration 380: 1354073.3\n",
      "Training loss at iteration 400: 1297103.5\n",
      "Training loss at iteration 420: 1247950.9\n",
      "Training loss at iteration 440: 1204402.2\n",
      "Training loss at iteration 460: 1166331.6\n",
      "Training loss at iteration 480: 1132618.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:53:05,516] Trial 11 finished with value: 1.1304165757188818 and parameters: {'num_features': 78, 'lambda': 2.019358253164037, 'learning_rate': 0.08109675912429483, 'iterations': 492}. Best is trial 10 with value: 1.0973299889007304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 42240203872.7\n",
      "Training loss at iteration 20: 545007061.8\n",
      "Training loss at iteration 40: 78530243.5\n",
      "Training loss at iteration 60: 18062168.1\n",
      "Training loss at iteration 80: 7443964.4\n",
      "Training loss at iteration 100: 4520481.4\n",
      "Training loss at iteration 120: 3267785.4\n",
      "Training loss at iteration 140: 2561202.9\n",
      "Training loss at iteration 160: 2107518.3\n",
      "Training loss at iteration 180: 1796010.4\n",
      "Training loss at iteration 200: 1572563.7\n",
      "Training loss at iteration 220: 1406865.1\n",
      "Training loss at iteration 240: 1280603.3\n",
      "Training loss at iteration 260: 1182150.1\n",
      "Training loss at iteration 280: 1103835.3\n",
      "Training loss at iteration 300: 1040439.6\n",
      "Training loss at iteration 320: 988316.1\n",
      "Training loss at iteration 340: 944858.1\n",
      "Training loss at iteration 360: 908164.8\n",
      "Training loss at iteration 380: 876825.6\n",
      "Training loss at iteration 400: 849776.6\n",
      "Training loss at iteration 420: 826204.6\n",
      "Training loss at iteration 440: 805479.4\n",
      "Training loss at iteration 460: 787107.5\n",
      "Training loss at iteration 480: 770697.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 17:57:06,138] Trial 12 finished with value: 0.9384011778903282 and parameters: {'num_features': 55, 'lambda': 1.7920209899189683, 'learning_rate': 0.09001293307956092, 'iterations': 498}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 42240362752.1\n",
      "Training loss at iteration 20: 2042441255.0\n",
      "Training loss at iteration 40: 370766215.0\n",
      "Training loss at iteration 60: 124652260.8\n",
      "Training loss at iteration 80: 60982984.0\n",
      "Training loss at iteration 100: 36104052.2\n",
      "Training loss at iteration 120: 23557430.2\n",
      "Training loss at iteration 140: 16358566.7\n",
      "Training loss at iteration 160: 11913551.8\n",
      "Training loss at iteration 180: 9022578.0\n",
      "Training loss at iteration 200: 7062276.2\n",
      "Training loss at iteration 220: 5685731.7\n",
      "Training loss at iteration 240: 4689876.5\n",
      "Training loss at iteration 260: 3950751.4\n",
      "Training loss at iteration 280: 3389878.8\n",
      "Training loss at iteration 300: 2955957.4\n",
      "Training loss at iteration 320: 2614489.9\n",
      "Training loss at iteration 340: 2341691.4\n",
      "Training loss at iteration 360: 2120794.8\n",
      "Training loss at iteration 380: 1939743.7\n",
      "Training loss at iteration 400: 1789714.0\n",
      "Training loss at iteration 420: 1664142.9\n",
      "Training loss at iteration 440: 1558078.7\n",
      "Training loss at iteration 460: 1467735.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:00:55,670] Trial 13 finished with value: 1.196736850663872 and parameters: {'num_features': 55, 'lambda': 2.29709820527597, 'learning_rate': 0.04366578558016941, 'iterations': 474}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 77720568561.5\n",
      "Training loss at iteration 20: 2813873904.2\n",
      "Training loss at iteration 40: 510479653.9\n",
      "Training loss at iteration 60: 170987897.3\n",
      "Training loss at iteration 80: 87898152.5\n",
      "Training loss at iteration 100: 55758266.2\n",
      "Training loss at iteration 120: 38842965.9\n",
      "Training loss at iteration 140: 28519090.2\n",
      "Training loss at iteration 160: 21736994.7\n",
      "Training loss at iteration 180: 17068163.5\n",
      "Training loss at iteration 200: 13737548.8\n",
      "Training loss at iteration 220: 11290999.1\n",
      "Training loss at iteration 240: 9448786.9\n",
      "Training loss at iteration 260: 8031836.5\n",
      "Training loss at iteration 280: 6921723.3\n",
      "Training loss at iteration 300: 6037893.1\n",
      "Training loss at iteration 320: 5324177.1\n",
      "Training loss at iteration 340: 4740571.9\n",
      "Training loss at iteration 360: 4257890.7\n",
      "Training loss at iteration 380: 3854697.8\n",
      "Training loss at iteration 400: 3514803.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:04:15,120] Trial 14 finished with value: 1.5372448990009944 and parameters: {'num_features': 101, 'lambda': 1.442200087703001, 'learning_rate': 0.0469884497243486, 'iterations': 409}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 40694985897.1\n",
      "Training loss at iteration 20: 2749690556.5\n",
      "Training loss at iteration 40: 538202227.2\n",
      "Training loss at iteration 60: 189968822.7\n",
      "Training loss at iteration 80: 93378021.2\n",
      "Training loss at iteration 100: 54450336.6\n",
      "Training loss at iteration 120: 34878267.4\n",
      "Training loss at iteration 140: 23806669.7\n",
      "Training loss at iteration 160: 17074150.7\n",
      "Training loss at iteration 180: 12755076.8\n",
      "Training loss at iteration 200: 9860968.2\n",
      "Training loss at iteration 220: 7849320.0\n",
      "Training loss at iteration 240: 6406736.7\n",
      "Training loss at iteration 260: 5344176.3\n",
      "Training loss at iteration 280: 4543222.6\n",
      "Training loss at iteration 300: 3927192.6\n",
      "Training loss at iteration 320: 3444950.0\n",
      "Training loss at iteration 340: 3061497.3\n",
      "Training loss at iteration 360: 2752324.8\n",
      "Training loss at iteration 380: 2499912.0\n",
      "Training loss at iteration 400: 2291502.6\n",
      "Training loss at iteration 420: 2117688.2\n",
      "Training loss at iteration 440: 1971281.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:07:53,610] Trial 15 finished with value: 1.2233303385776138 and parameters: {'num_features': 54, 'lambda': 3.0798897573140684, 'learning_rate': 0.03755850507763781, 'iterations': 451}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 98291043108.1\n",
      "Training loss at iteration 20: 57392091322.1\n",
      "Training loss at iteration 40: 35295250032.6\n",
      "Training loss at iteration 60: 23066777555.3\n",
      "Training loss at iteration 80: 15849244878.7\n",
      "Training loss at iteration 100: 11310313387.1\n",
      "Training loss at iteration 120: 8312216730.6\n",
      "Training loss at iteration 140: 6257913157.3\n",
      "Training loss at iteration 160: 4809632263.1\n",
      "Training loss at iteration 180: 3764427241.6\n",
      "Training loss at iteration 200: 2994742888.8\n",
      "Training loss at iteration 220: 2417659452.1\n",
      "Training loss at iteration 240: 1977844581.3\n",
      "Training loss at iteration 260: 1637576899.6\n",
      "Training loss at iteration 280: 1370662372.6\n",
      "Training loss at iteration 300: 1158607501.9\n",
      "Training loss at iteration 320: 988153708.2\n",
      "Training loss at iteration 340: 849657605.5\n",
      "Training loss at iteration 360: 736009179.2\n",
      "Training loss at iteration 380: 641898410.3\n",
      "Training loss at iteration 400: 563311185.1\n",
      "Training loss at iteration 420: 497178206.3\n",
      "Training loss at iteration 440: 441127342.8\n",
      "Training loss at iteration 460: 393306789.2\n",
      "Training loss at iteration 480: 352257292.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:11:55,674] Trial 16 finished with value: 2.258427380843108 and parameters: {'num_features': 129, 'lambda': 1.8055311272988162, 'learning_rate': 0.005777958551899303, 'iterations': 500}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 66531593869.8\n",
      "Training loss at iteration 20: 865629111.9\n",
      "Training loss at iteration 40: 117846468.0\n",
      "Training loss at iteration 60: 27550131.6\n",
      "Training loss at iteration 80: 11803558.1\n",
      "Training loss at iteration 100: 7462808.9\n",
      "Training loss at iteration 120: 5575332.8\n",
      "Training loss at iteration 140: 4489706.0\n",
      "Training loss at iteration 160: 3782250.4\n",
      "Training loss at iteration 180: 3283992.1\n",
      "Training loss at iteration 200: 2921568.1\n",
      "Training loss at iteration 220: 2648430.6\n",
      "Training loss at iteration 240: 2436590.7\n",
      "Training loss at iteration 260: 2268378.5\n",
      "Training loss at iteration 280: 2132045.6\n",
      "Training loss at iteration 300: 2019549.2\n",
      "Training loss at iteration 320: 1925233.8\n",
      "Training loss at iteration 340: 1847282.2\n",
      "Training loss at iteration 360: 1777247.1\n",
      "Training loss at iteration 380: 1715778.2\n",
      "Training loss at iteration 400: 1662850.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:15:11,494] Trial 17 finished with value: 1.1517574861980566 and parameters: {'num_features': 86, 'lambda': 3.4516562717607244, 'learning_rate': 0.09409468815225983, 'iterations': 403}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 119760736158.2\n",
      "Training loss at iteration 20: 3227689234.7\n",
      "Training loss at iteration 40: 560138247.3\n",
      "Training loss at iteration 60: 172614287.9\n",
      "Training loss at iteration 80: 87385242.8\n",
      "Training loss at iteration 100: 56922848.2\n",
      "Training loss at iteration 120: 41177900.4\n",
      "Training loss at iteration 140: 31413375.2\n",
      "Training loss at iteration 160: 24834976.9\n",
      "Training loss at iteration 180: 20187588.2\n",
      "Training loss at iteration 200: 16790243.2\n",
      "Training loss at iteration 220: 14237585.9\n",
      "Training loss at iteration 240: 12274900.9\n",
      "Training loss at iteration 260: 10735788.1\n",
      "Training loss at iteration 280: 9507893.5\n",
      "Training loss at iteration 300: 8513487.0\n",
      "Training loss at iteration 320: 7697407.6\n",
      "Training loss at iteration 340: 7019679.7\n",
      "Training loss at iteration 360: 6450861.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:18:15,368] Trial 18 finished with value: 1.9048703237234987 and parameters: {'num_features': 156, 'lambda': 2.8427860964397675, 'learning_rate': 0.05274986959620834, 'iterations': 380}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 56543814891.7\n",
      "Training loss at iteration 20: 5985209085.8\n",
      "Training loss at iteration 40: 1384133725.2\n",
      "Training loss at iteration 60: 535180147.0\n",
      "Training loss at iteration 80: 272947410.7\n",
      "Training loss at iteration 100: 160788925.3\n",
      "Training loss at iteration 120: 103019002.4\n",
      "Training loss at iteration 140: 70000294.2\n",
      "Training loss at iteration 160: 49793159.9\n",
      "Training loss at iteration 180: 36766623.6\n",
      "Training loss at iteration 200: 28004419.8\n",
      "Training loss at iteration 220: 21896131.7\n",
      "Training loss at iteration 240: 17506323.1\n",
      "Training loss at iteration 260: 14267955.4\n",
      "Training loss at iteration 280: 11824356.3\n",
      "Training loss at iteration 300: 9943813.2\n",
      "Training loss at iteration 320: 8471408.7\n",
      "Training loss at iteration 340: 7300911.0\n",
      "Training loss at iteration 360: 6357799.8\n",
      "Training loss at iteration 380: 5588725.3\n",
      "Training loss at iteration 400: 4954788.5\n",
      "Training loss at iteration 420: 4427153.4\n",
      "Training loss at iteration 440: 3984123.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:21:56,671] Trial 19 finished with value: 1.59169538931242 and parameters: {'num_features': 74, 'lambda': 1.2693482789091652, 'learning_rate': 0.029296086675554986, 'iterations': 455}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 100550176363.8\n",
      "Training loss at iteration 20: 1258932612.4\n",
      "Training loss at iteration 40: 161796138.1\n",
      "Training loss at iteration 60: 36453837.0\n",
      "Training loss at iteration 80: 15448759.5\n",
      "Training loss at iteration 100: 9889934.4\n",
      "Training loss at iteration 120: 7529335.4\n",
      "Training loss at iteration 140: 6173648.6\n",
      "Training loss at iteration 160: 5281529.0\n",
      "Training loss at iteration 180: 4653603.2\n",
      "Training loss at iteration 200: 4192017.7\n",
      "Training loss at iteration 220: 3841276.1\n",
      "Training loss at iteration 240: 3568340.3\n",
      "Training loss at iteration 260: 3348413.5\n",
      "Training loss at iteration 280: 3168891.9\n",
      "Training loss at iteration 300: 3020059.3\n",
      "Training loss at iteration 320: 2894325.9\n",
      "Training loss at iteration 340: 2786747.9\n",
      "Training loss at iteration 360: 2693133.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:24:57,020] Trial 20 finished with value: 1.3869260288979863 and parameters: {'num_features': 131, 'lambda': 3.705799150562887, 'learning_rate': 0.09984228827239204, 'iterations': 372}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 56544154333.9\n",
      "Training loss at iteration 20: 1216597225.5\n",
      "Training loss at iteration 40: 193992406.1\n",
      "Training loss at iteration 60: 55561756.5\n",
      "Training loss at iteration 80: 26403521.6\n",
      "Training loss at iteration 100: 16531343.2\n",
      "Training loss at iteration 120: 11666728.5\n",
      "Training loss at iteration 140: 8752102.0\n",
      "Training loss at iteration 160: 6839018.6\n",
      "Training loss at iteration 180: 5516440.0\n",
      "Training loss at iteration 200: 4567963.7\n",
      "Training loss at iteration 220: 3867702.4\n",
      "Training loss at iteration 240: 3337984.7\n",
      "Training loss at iteration 260: 2928846.0\n",
      "Training loss at iteration 280: 2607060.2\n",
      "Training loss at iteration 300: 2349906.2\n",
      "Training loss at iteration 320: 2141467.6\n",
      "Training loss at iteration 340: 1970355.4\n",
      "Training loss at iteration 360: 1828265.4\n",
      "Training loss at iteration 380: 1709040.0\n",
      "Training loss at iteration 400: 1608043.2\n",
      "Training loss at iteration 420: 1521736.4\n",
      "Training loss at iteration 440: 1447385.4\n",
      "Training loss at iteration 460: 1382852.5\n",
      "Training loss at iteration 480: 1326449.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:28:55,626] Trial 21 finished with value: 1.2668028172399377 and parameters: {'num_features': 74, 'lambda': 2.07000712042949, 'learning_rate': 0.0635808547877157, 'iterations': 493}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 38599854351.4\n",
      "Training loss at iteration 20: 35267329566.1\n",
      "Training loss at iteration 40: 32287713714.4\n",
      "Training loss at iteration 60: 29640876074.5\n",
      "Training loss at iteration 80: 27283596696.3\n",
      "Training loss at iteration 100: 25174518958.6\n",
      "Training loss at iteration 120: 23279284405.6\n",
      "Training loss at iteration 140: 21569727566.6\n",
      "Training loss at iteration 160: 20022494526.2\n",
      "Training loss at iteration 180: 18617973327.5\n",
      "Training loss at iteration 200: 17339522162.9\n",
      "Training loss at iteration 220: 16172901643.6\n",
      "Training loss at iteration 240: 15105844861.3\n",
      "Training loss at iteration 260: 14127723587.4\n",
      "Training loss at iteration 280: 13229283949.1\n",
      "Training loss at iteration 300: 12402433830.5\n",
      "Training loss at iteration 320: 11640069714.7\n",
      "Training loss at iteration 340: 10935934177.1\n",
      "Training loss at iteration 360: 10284497577.0\n",
      "Training loss at iteration 380: 9680859102.4\n",
      "Training loss at iteration 400: 9120663466.6\n",
      "Training loss at iteration 420: 8600030379.3\n",
      "Training loss at iteration 440: 8115494531.1\n",
      "Training loss at iteration 460: 7663954286.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:32:47,231] Trial 22 finished with value: 2.403384266911131 and parameters: {'num_features': 50, 'lambda': 1.7456236745756035, 'learning_rate': 0.0011178962453037775, 'iterations': 478}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 66521706284.7\n",
      "Training loss at iteration 20: 1363220608.3\n",
      "Training loss at iteration 40: 218080734.4\n",
      "Training loss at iteration 60: 62346532.4\n",
      "Training loss at iteration 80: 29817917.3\n",
      "Training loss at iteration 100: 18908354.6\n",
      "Training loss at iteration 120: 13531083.6\n",
      "Training loss at iteration 140: 10286620.7\n",
      "Training loss at iteration 160: 8137267.5\n",
      "Training loss at iteration 180: 6636754.8\n",
      "Training loss at iteration 200: 5550187.0\n",
      "Training loss at iteration 220: 4740374.2\n",
      "Training loss at iteration 240: 4122214.2\n",
      "Training loss at iteration 260: 3640578.2\n",
      "Training loss at iteration 280: 3258595.3\n",
      "Training loss at iteration 300: 2950905.1\n",
      "Training loss at iteration 320: 2699595.8\n",
      "Training loss at iteration 340: 2491778.0\n",
      "Training loss at iteration 360: 2317994.4\n",
      "Training loss at iteration 380: 2171189.9\n",
      "Training loss at iteration 400: 2046039.4\n",
      "Training loss at iteration 420: 1938390.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:36:17,704] Trial 23 finished with value: 1.3379463482379748 and parameters: {'num_features': 87, 'lambda': 2.4764707697674186, 'learning_rate': 0.06503013217197169, 'iterations': 434}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 84491121514.1\n",
      "Training loss at iteration 20: 5940363784.0\n",
      "Training loss at iteration 40: 1242400195.0\n",
      "Training loss at iteration 60: 467642140.8\n",
      "Training loss at iteration 80: 246350897.8\n",
      "Training loss at iteration 100: 153176480.9\n",
      "Training loss at iteration 120: 103732089.5\n",
      "Training loss at iteration 140: 74188262.5\n",
      "Training loss at iteration 160: 55264783.4\n",
      "Training loss at iteration 180: 42529420.0\n",
      "Training loss at iteration 200: 33616193.8\n",
      "Training loss at iteration 220: 27172439.4\n",
      "Training loss at iteration 240: 22384716.3\n",
      "Training loss at iteration 260: 18743287.9\n",
      "Training loss at iteration 280: 15917332.1\n",
      "Training loss at iteration 300: 13685504.5\n",
      "Training loss at iteration 320: 11895692.6\n",
      "Training loss at iteration 340: 10440862.3\n",
      "Training loss at iteration 360: 9244112.3\n",
      "Training loss at iteration 380: 8249056.5\n",
      "Training loss at iteration 400: 7413778.2\n",
      "Training loss at iteration 420: 6706546.2\n",
      "Training loss at iteration 440: 6103023.0\n",
      "Training loss at iteration 460: 5584320.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-04 18:40:04,875] Trial 24 finished with value: 1.647171514056583 and parameters: {'num_features': 110, 'lambda': 1.5682243496989827, 'learning_rate': 0.03354708660953918, 'iterations': 469}. Best is trial 12 with value: 0.9384011778903282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres trouvés:  {'num_features': 55, 'lambda': 1.7920209899189683, 'learning_rate': 0.09001293307956092, 'iterations': 498}\n",
      "Meilleure MAE:  0.9384011778903282\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"62b0c7fb-64a0-4c7e-a5cc-d7ba9e86cc97\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"62b0c7fb-64a0-4c7e-a5cc-d7ba9e86cc97\")) {                    Plotly.newPlot(                        \"62b0c7fb-64a0-4c7e-a5cc-d7ba9e86cc97\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"lambda (FloatDistribution): 0.008603885830696276\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"iterations (IntDistribution): 0.020498290348604044\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"num_features (IntDistribution): 0.2984252655217844\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.6724725582989152\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"0.02\",\"0.30\",\"0.67\"],\"textposition\":\"outside\",\"x\":[0.008603885830696276,0.020498290348604044,0.2984252655217844,0.6724725582989152],\"y\":[\"lambda\",\"iterations\",\"num_features\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('62b0c7fb-64a0-4c7e-a5cc-d7ba9e86cc97');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Définition des hyperparamètres à optimiser\n",
    "    # Les valeurs bornes ont été trouvées après plusieurs essais avec optuna\n",
    "    num_features = trial.suggest_int('num_features', 50, 250)\n",
    "    lambda_ = trial.suggest_float('lambda', 1e0, 1e1, log=True)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
    "    iterations = trial.suggest_int('iterations', 200, 500)\n",
    "\n",
    "    # Création et entraînement du modèle\n",
    "    # Utilisation de R * (Y_train > 0) pour séparer totalement le train set du reste et ne prendre en compte\n",
    "    # que les films notés du train set\n",
    "    recommender = MovieRecommender(num_users, num_movies, num_features, num_movie_features, movie_features)\n",
    "    recommender.fit(Ynorm, Ymean, R * (Y_train > 0), iterations, lambda_, learning_rate)\n",
    "\n",
    "    # Évaluation du modèle sur le set de validation\n",
    "    mae = recommender.getError(Y_val, movieList)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Création d'une étude Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Affichage des meilleurs résultats\n",
    "print(\"Meilleurs hyperparamètres trouvés: \", best_params)\n",
    "print(\"Meilleure MAE: \", study.best_value)\n",
    "\n",
    "# Visualisation de l'importance des hyperparamètres\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8285e",
   "metadata": {
    "papermill": {
     "duration": 0.046249,
     "end_time": "2024-07-04T18:40:06.120270",
     "exception": false,
     "start_time": "2024-07-04T18:40:06.074021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6640784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T18:40:06.214582Z",
     "iopub.status.busy": "2024-07-04T18:40:06.214280Z",
     "iopub.status.idle": "2024-07-04T18:44:08.114497Z",
     "shell.execute_reply": "2024-07-04T18:44:08.113340Z"
    },
    "papermill": {
     "duration": 241.949936,
     "end_time": "2024-07-04T18:44:08.116513",
     "exception": false,
     "start_time": "2024-07-04T18:40:06.166577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 42240203872.7\n",
      "Training loss at iteration 20: 545007061.8\n",
      "Training loss at iteration 40: 78530243.5\n",
      "Training loss at iteration 60: 18062168.1\n",
      "Training loss at iteration 80: 7443964.4\n",
      "Training loss at iteration 100: 4520481.4\n",
      "Training loss at iteration 120: 3267785.4\n",
      "Training loss at iteration 140: 2561202.9\n",
      "Training loss at iteration 160: 2107518.3\n",
      "Training loss at iteration 180: 1796010.4\n",
      "Training loss at iteration 200: 1572563.7\n",
      "Training loss at iteration 220: 1406865.1\n",
      "Training loss at iteration 240: 1280603.3\n",
      "Training loss at iteration 260: 1182150.1\n",
      "Training loss at iteration 280: 1103835.3\n",
      "Training loss at iteration 300: 1040439.6\n",
      "Training loss at iteration 320: 988316.1\n",
      "Training loss at iteration 340: 944858.1\n",
      "Training loss at iteration 360: 908164.8\n",
      "Training loss at iteration 380: 876825.6\n",
      "Training loss at iteration 400: 849776.6\n",
      "Training loss at iteration 420: 826204.6\n",
      "Training loss at iteration 440: 805479.4\n",
      "Training loss at iteration 460: 787107.5\n",
      "Training loss at iteration 480: 770697.9\n",
      "\n",
      "\n",
      "Erreur absolue moyenne sur val set(MAE) : 0.9384011778903282\n",
      "\n",
      "\n",
      "Erreur absolue moyenne sur test set(MAE) : 1.0014011104509344\n"
     ]
    }
   ],
   "source": [
    "# Utilisation des meilleurs paramètres pour entrainer notre modèle\n",
    "recommender_final = MovieRecommender(num_users, num_movies, best_params['num_features'], num_movie_features, movie_features)\n",
    "recommender_final.fit(Ynorm, Ymean, R * (Y_train >0), best_params['iterations'], best_params['lambda'], best_params['learning_rate'])\n",
    "\n",
    "# Obtention de l'erreur moyenne de notre modèle sur le validation set et le test set pour visualiser ses performances\n",
    "mae_val = recommender_final.getError(Y_val, movieList)\n",
    "mae_test = recommender_final.getError(Y_test, movieList)\n",
    "\n",
    "print(f\"\\n\\nErreur absolue moyenne sur val set(MAE) : {mae_val}\")\n",
    "print(f\"\\n\\nErreur absolue moyenne sur test set(MAE) : {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c282c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T18:44:08.217125Z",
     "iopub.status.busy": "2024-07-04T18:44:08.216516Z",
     "iopub.status.idle": "2024-07-04T18:44:08.538619Z",
     "shell.execute_reply": "2024-07-04T18:44:08.537696Z"
    },
    "papermill": {
     "duration": 0.373661,
     "end_time": "2024-07-04T18:44:08.540690",
     "exception": false,
     "start_time": "2024-07-04T18:44:08.167029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_id': 9, 'title': 'Sudden Death', 'couple_score': 6.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recommendation pour les utilisateurs 1 et 2\n",
    "best_movie = recommender_final.getMovieRecommendation(1,2, df_movies, R)\n",
    "best_movie"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5306058,
     "sourceId": 8819972,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5326782,
     "sourceId": 8849594,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5141.739592,
   "end_time": "2024-07-04T18:44:11.118486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-04T17:18:29.378894",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
