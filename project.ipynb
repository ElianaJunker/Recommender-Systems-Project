{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:37:26.126771Z","iopub.status.busy":"2024-07-05T13:37:26.125980Z","iopub.status.idle":"2024-07-05T13:37:40.124697Z","shell.execute_reply":"2024-07-05T13:37:40.123874Z","shell.execute_reply.started":"2024-07-05T13:37:26.126721Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-05 13:37:29.932466: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-05 13:37:29.932580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-05 13:37:30.055888: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import random\n","from typing import TypeVar, Tuple, Union\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n","from sklearn.metrics import precision_score\n","import tensorflow as tf\n","\n","import optuna\n","\n","Self = TypeVar(\"Self\")"]},{"cell_type":"markdown","metadata":{},"source":["# Chargement des datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%bash\n","if [ ! -d \"./data/movielens_complete\" ]; \n","then    \n","    wget http://files.grouplens.org/datasets/movielens/ml-1m.zip \n","    mkdir -p ./data/movielens_complete\n","    unzip -o ml-1m.zip -d ./data/movielens_complete;\n","else\n","    echo \"Data already downloaded\";\n","fi"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%bash\n","if [ ! -d \"./data/IMDb\" ]; \n","then    \n","    wget https://datasets.imdbws.com/title.basics.tsv.gz\n","    wget https://datasets.imdbws.com/title.crew.tsv.gz\n","    wget https://datasets.imdbws.com/title.ratings.tsv.gz\n","    mkdir -p ./data/IMDb\n","    gzip -dc title.basics.tsv.gz > ./data/IMDb/title.basics.tsv\n","    gzip -dc title.crew.tsv.gz > ./data/IMDb/title.crew.tsv\n","    gzip -dc title.ratings.tsv.gz > ./data/IMDb/title.ratings.tsv\n","else\n","    echo \"Data already downloaded\";\n","fi"]},{"cell_type":"markdown","metadata":{},"source":["# Fonctions utiles"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:37:40.127241Z","iopub.status.busy":"2024-07-05T13:37:40.126706Z","iopub.status.idle":"2024-07-05T13:37:40.149108Z","shell.execute_reply":"2024-07-05T13:37:40.148099Z","shell.execute_reply.started":"2024-07-05T13:37:40.127214Z"},"trusted":true},"outputs":[],"source":["def extract_year_and_title(row):\n","    \"\"\"\n","    Fonction qui extrait l'année d'une chaine de caractères.\n","    Cela permet de séparer l'année et le titre d'un film\n","    \n","    Paramètres:\n","    ----------\n","    row: string\n","        la phrase contenant le titre et l'année de sortie\n","    \n","    Retours:\n","    -------\n","    Tuple[String, String]\n","        le titre du film et son année\n","    \"\"\"\n","    match = re.search(r'\\((\\d{4})\\)$', row)\n","    if match:\n","        year = match.group(1)\n","        title = row[:match.start()].strip()\n","    else:\n","        year = None\n","        title = row\n","    return title, year\n","\n","\n","def combine_genres(row):\n","    \"\"\"\n","    Fonction pour combiner les genres des deux colonnes en une chaine de caractère (sans les dupliqués)\n","    \n","    Paramètres:\n","    ----------\n","    row: dataframe pandas\n","        la ligne du dataframe qui contient les deux colonnes (genre_x et genre_y)\n","    \n","    Retours:\n","    -------\n","    String\n","        l'ensemble des genres séparés par des ','\n","    \"\"\"\n","    genrex = row['genres_x']\n","    genrey = row['genres_y']\n","    genres = genrex.split('|') + (genrey.split(',') if pd.notna(row['genres_y']) else [])\n","    #enlever les doublons\n","    unique_genres = list(set(genres))\n","    #recréer une string séparée par des ','\n","    return ','.join(unique_genres)\n","\n","\n","def split_ratings(\n","    ratings: np.ndarray, \n","    val_size: Union[float, int], \n","    test_size: Union[float, int]\n",") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n","    \"\"\"Fonction pour créer des ensembles de validation et de test à partir d'une matrice de notes\n","\n","    Paramètres:\n","    ----------\n","    ratings : np.ndarray\n","        La matrice des notes (peut être clairsemée, remplie de zéros ou de valeurs manquantes).\n","    val_size : float ou int\n","        La taille de l'ensemble de validation.\n","        Si float, la taille est exprimée en pourcentage de la taille totale du tableau des notes.\n","        Si int, la taille est exprimée en nombre brut de notes dans l'ensemble de validation.\n","    test_size : float ou int\n","        La taille de l'ensemble de test.\n","        Si float, la taille est exprimée en pourcentage de la taille totale du tableau des notes.\n","        Si int, la taille est exprimée en nombre brut de notes dans l'ensemble de test.\n","\n","    Retours:\n","    -------\n","    Tuple[np.ndarray, np.ndarray, np.ndarray]\n","        Le tuple des notes d'entraînement, de validation et de test.\n","    \"\"\"\n","    #Prépare les 3 matrices de résultats\n","    rows, cols = np.where(ratings > 0)\n","    val_ratings = np.zeros(ratings.shape)\n","    test_ratings = np.zeros(ratings.shape)\n","    train_ratings = ratings.copy()\n","\n","    total_ratings = len(rows)\n","\n","    if val_size < 1:  # si c'est un pourcentage\n","        val_size = int(total_ratings * val_size)\n","    if test_size < 1:  # si c'est un pourcentage\n","        test_size = int(total_ratings * test_size)\n","\n","    total_sample_size = val_size + test_size\n","\n","    # Récupère aléatoirement les indices pour le set de validation et de test\n","    sample_indices = random.sample(range(total_ratings), total_sample_size)\n","    val_indices = sample_indices[:val_size]\n","    test_indices = sample_indices[val_size:]\n","\n","    # Remplis le set de validation\n","    for idx in val_indices:\n","        row, col = rows[idx], cols[idx]\n","        #permet de les enlever du set d'entraînement pour les séparer totalement\n","        train_ratings[row, col] = 0\n","        val_ratings[row, col] = ratings[row, col]\n","\n","    # Remplis le set de test\n","    for idx in test_indices:\n","        row, col = rows[idx], cols[idx]\n","        #permet de les enlever du set d'entraînement pour les séparer totalement\n","        train_ratings[row, col] = 0\n","        test_ratings[row, col] = ratings[row, col]\n","\n","    return train_ratings, val_ratings, test_ratings\n","\n","\n","def normalizeRatings(Y: np.ndarray, R: np.ndarray, axis: int = 1) -> Tuple:\n","    \"\"\"\n","    Prétraiter les données en soustrayant la note moyenne pour chaque film (chaque ligne).\n","    Inclure uniquement les notes réelles : R(i,j)=1.\n","\n","    [Ynorm, Ymean] = normalizeRatings(Y, R) normalise Y pour que chaque film\n","    ait une note de 0 en moyenne. Les films non notés ont alors une note moyenne (0)\n","    Renvoie la note moyenne dans Ymean.\n","\n","    Paramètres:\n","    ----------\n","    Y : np.ndarray\n","        Le tableau de notes à normaliser.\n","    R : np.ndarray\n","        Le tableau indiquant si un utilisateur a noté un film.\n","    axis : int\n","        L'axe numpy à utiliser pour calculer la note moyenne.\n","\n","    Retours:\n","    -------\n","    Tuple\n","        Le tableau normalisé des notes et la note moyenne.\n","    \"\"\"\n","    Ymean = (np.sum(Y * R, axis=axis) / (np.sum(R, axis=axis) + 1e-12)).reshape(-1, 1)\n","\n","    if axis == 0:\n","        Ynorm = Y.T - np.multiply(Ymean, R.T)\n","    else:\n","        Ynorm = Y - np.multiply(Ymean, R)\n","\n","    return (Ynorm, Ymean)\n","\n","\n","def cofi_cost_func_v(X, W, W_features, b, Y, R,movie_features, lambda_):\n","    \"\"\"\n","    Renvoie le coût pour le filtrage basé sur le contenu\n","    Vectorisé pour la vitesse. Utilise les opérations TensorFlow pour être compatible avec une boucle d'entraînement personnalisée.\n","\n","    Paramètres:\n","    -----------\n","    X: np.ndarray (num_movies,num_features)\n","        Matrice des caractéristiques des items\n","    W: np.ndarray (num_users,num_features)\n","        Matrice des paramètres des utilisateurs\n","    W_features: np.ndarray (num_movie_features, num_features)\n","        Matrice de poids des features des films\n","    b: np.ndarray (1, num_users)\n","        Vecteur des paramètres des utilisateurs\n","    Y: np.ndarray (num_movies,num_users)\n","        Matrice des notes des utilisateurs pour les films\n","    R: np.ndarray (num_movies,num_users)\n","        Matrice où R(i, j) = 1 si le i-ème film a été noté par le j-ème utilisateur\n","    movie_features: np.ndarray\n","        Matrice des features des films\n","    lambda_: float\n","        Paramètre de régularisation\n","\n","    Retours:\n","    -------\n","    float\n","        La valeur du coût étant donné les paramètres.\n","    \"\"\"\n","    #Calcule le biais apportés par les caractéristiques (features) des films\n","    movie_bias = tf.matmul(movie_features, W_features)\n","    \n","    # On ajoute ce biais aux caractéristiques déjà connues (X) pour prendre en compte l'influence\n","    # des features sur les notes des utilisateurs (= ajouts de nouvelles caractéristiques) \n","    j = (tf.linalg.matmul(X + movie_bias, tf.transpose(W)) + b - Y) * R\n","    J = 0.5 * tf.reduce_sum(j**2) + (lambda_ / 2) * (\n","        tf.reduce_sum(X**2) + tf.reduce_sum(W**2) + tf.reduce_sum(W_features**2)\n","    )\n","    return J"]},{"cell_type":"markdown","metadata":{},"source":["# Chargement et traitements des données"]},{"cell_type":"markdown","metadata":{},"source":["#### Chargement de movieLens (movies et ratings)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:37:40.150732Z","iopub.status.busy":"2024-07-05T13:37:40.150381Z","iopub.status.idle":"2024-07-05T13:37:48.653244Z","shell.execute_reply":"2024-07-05T13:37:48.652439Z","shell.execute_reply.started":"2024-07-05T13:37:40.150701Z"},"trusted":true},"outputs":[],"source":["#Movies\n","df_movies1 = pd.read_csv(\n","        \"./data/movielens_complete/ml-1m/movies.dat\",\n","        sep=\"::\",\n","        encoding='ISO-8859-1',\n","        engine='python',\n","        header=None\n","    )\n","\n","df_movies1.columns = [\"movieId\", \"title\", \"genres\"]\n","\n","#Séparation des titres en titre et années pour pouvoir le lier à l'autre dataset\n","df_movies1['title'], df_movies1['year'] = zip(*df_movies1['title'].map(extract_year_and_title))\n","\n","\n","#Ratings\n","df_ratings1 = pd.read_csv(\n","        \"./data/movielens_complete/ml-1m/ratings.dat\",\n","        sep=\"::\",\n","        encoding='ISO-8859-1',\n","        engine='python',\n","        header=None\n","    )\n","\n","df_ratings1.columns = [\"userId\",\"movieId\",\"Rating\",\"timestamp\"]\n","\n","\n","#matrice d'interaction utilisateur-films\n","df_matrix = df_ratings1.pivot(index=\"movieId\", columns=\"userId\", values=\"Rating\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Chargement de IMbd (titleBasics, title_crew et ratings)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:37:48.655672Z","iopub.status.busy":"2024-07-05T13:37:48.655382Z","iopub.status.idle":"2024-07-05T13:38:42.096798Z","shell.execute_reply":"2024-07-05T13:38:42.095761Z","shell.execute_reply.started":"2024-07-05T13:37:48.655647Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/3002934010.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_movies2 = pd.read_csv(\n"]}],"source":["#Chargement de titleBasics\n","df_movies2 = pd.read_csv(\n","        \"./data/IMDb/title.basics.tsv\",\n","        sep='\\t'\n","    )\n","\n","#Surpression de tout ce qui n'est pas un movie pour pouvoir le combiner plus tard\n","df_movies2.drop(df_movies2[df_movies2['titleType'] != 'movie'].index, inplace=True)\n","\n","\n","#Chargement de titleCrew\n","df_crew = pd.read_csv(\n","        \"./data/IMDb/title.crew.tsv\",\n","        sep='\\t'\n","    )\n","\n","df_crew.drop(columns=['writers'], inplace=True)\n","\n","#chargement de ratings\n","df_ratings2 = pd.read_csv(\n","        \"./data/IMDb/title.ratings.tsv\",\n","        sep='\\t'\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["#### Merge des deux datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:38:42.098558Z","iopub.status.busy":"2024-07-05T13:38:42.098166Z","iopub.status.idle":"2024-07-05T13:38:52.657717Z","shell.execute_reply":"2024-07-05T13:38:52.656786Z","shell.execute_reply.started":"2024-07-05T13:38:42.098521Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/970431456.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df_movies['isAdult'] = df_movies['isAdult'].fillna(0)\n"]}],"source":["#merge des datasets movies pour obtenir plus de metadata\n","df_movies = pd.merge(df_movies1, df_movies2, left_on=['title', 'year'], right_on=['primaryTitle', 'startYear'], how='left')\n","df_movies.drop_duplicates(subset='movieId', keep='first', inplace=True)\n"," \n","#merge des movies et de ratings pour avoir les notes moyennes en metadata\n","df_movies = pd.merge(df_movies, df_ratings2, on='tconst', how='left')\n","\n","#merge de movies et de crew pour avoir les directors en metadata\n","df_movies = pd.merge(df_movies, df_crew, on='tconst', how='left')\n","\n","#nettoyage du df_movies\n","df_movies['genres'] = df_movies.apply(combine_genres, axis=1)\n","df_movies['directors'] = df_movies['directors'].fillna('')\n","df_movies['isAdult'] = df_movies['isAdult'].fillna(0)\n","#pour ne pas mettre 0 et influencer les choix trop négativement pour ces films, on remplace les nan par la moyenne des averageRating\n","df_movies['averageRating'] = df_movies['averageRating'].fillna(df_movies['averageRating'].mean())\n","df_movies['averageRating'] = df_movies['averageRating'] / 2\n","df_movies.drop(columns=['tconst', 'titleType', 'primaryTitle', 'originalTitle', 'startYear', 'endYear', 'runtimeMinutes', 'genres_x', 'genres_y'], inplace=True)\n","\n","# Rajout des films qui n'ont jamais été notés pour permettre l'utilisation des features plus tard\n","movie_ids_in_movies = set(df_movies['movieId'])\n","movie_ids_in_ratings = set(df_matrix.index)\n","missing_movie_ids = movie_ids_in_movies - movie_ids_in_ratings\n","new_entries = pd.DataFrame(np.nan, index=list(missing_movie_ids), columns=df_matrix.columns)\n","df_matrix = pd.concat([df_matrix, new_entries], ignore_index=False)"]},{"cell_type":"markdown","metadata":{},"source":["#### Création des np.array pour le collaborative filtering"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:38:52.659141Z","iopub.status.busy":"2024-07-05T13:38:52.658869Z","iopub.status.idle":"2024-07-05T13:38:52.815030Z","shell.execute_reply":"2024-07-05T13:38:52.814212Z","shell.execute_reply.started":"2024-07-05T13:38:52.659117Z"},"trusted":true},"outputs":[],"source":["R = df_matrix.notna().astype(int).to_numpy()\n","df_matrix = df_matrix.fillna(0)\n","Y = df_matrix.to_numpy()"]},{"cell_type":"markdown","metadata":{},"source":["# Features_engineering\n","\n","- encodage des genres et des directors en matrice binaire pour être utilisés comme features\n","- utilisation de isAdult et de averageRating (remis sur 5) comme features\n","- scaling de la matrice de features pour donner le même poids à chacune d'entre elles et pour lui permettre d'être utilisée plus tard dans l'entraînement\n","\n","Genres et directors sont choisis car les gens ont souvent des préférences pour des genres ou des préférences pour certains directeurs de films.\n","\n","isAdult est choisi car certaines personnes peuvent préférer des films considérés comme pour les adultes plutôt que des films plus enfantins.\n","\n","averageRating est choisi car c'est une donnée que les gens peuvent regarder pour choisir un film (si un film est bien noté en moyenne, on aura tendance à le préférer). Cela peut également aider si un film n'est pas beaucoup noté ou n'est pas du tout noté par les utilisateurs."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:38:52.816664Z","iopub.status.busy":"2024-07-05T13:38:52.816283Z","iopub.status.idle":"2024-07-05T13:38:53.748456Z","shell.execute_reply":"2024-07-05T13:38:53.747670Z","shell.execute_reply.started":"2024-07-05T13:38:52.816631Z"},"trusted":true},"outputs":[],"source":["#transformation des strings en liste pour être utilisé par MultiLabelBinarizer\n","df_movies['genres'] = df_movies['genres'].apply(lambda x: x.split(','))\n","df_movies['directors'] = df_movies['directors'].apply(lambda x: x.split(','))\n","\n","# Transformation en matrice binaire\n","genres_mlb = MultiLabelBinarizer()\n","genres_encoded = genres_mlb.fit_transform(df_movies['genres'])\n","genres_df = pd.DataFrame(genres_encoded, columns=genres_mlb.classes_)\n","\n","directors_mlb = MultiLabelBinarizer()\n","directors_encoded = directors_mlb.fit_transform(df_movies['directors'])\n","directors_df = pd.DataFrame(directors_encoded, columns=directors_mlb.classes_)\n","\n","features = pd.concat([genres_df,directors_df, df_movies[['isAdult', 'averageRating']]], axis=1)\n","\n","# Scaling de la matrice de features\n","scaler = StandardScaler()\n","features_scaled = scaler.fit_transform(features)\n","\n","movie_features = tf.constant(features_scaled, dtype=tf.float64)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:38:53.749732Z","iopub.status.busy":"2024-07-05T13:38:53.749466Z","iopub.status.idle":"2024-07-05T13:38:54.164764Z","shell.execute_reply":"2024-07-05T13:38:54.163965Z","shell.execute_reply.started":"2024-07-05T13:38:53.749709Z"},"trusted":true},"outputs":[],"source":["#  Données utiles\n","num_movies, num_users = Y.shape\n","num_movie_features = movie_features.shape[1]\n","movieList = df_movies[\"title\"].to_list()\n","\n","#Séparation en train, val et test\n","Y_train, Y_val, Y_test = split_ratings(Y, val_size=627, test_size=626)\n","Ynorm, Ymean = normalizeRatings(Y_train, R)"]},{"cell_type":"markdown","metadata":{},"source":["# Modèle de recommendation"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:38:54.166264Z","iopub.status.busy":"2024-07-05T13:38:54.165993Z","iopub.status.idle":"2024-07-05T13:38:54.195173Z","shell.execute_reply":"2024-07-05T13:38:54.194175Z","shell.execute_reply.started":"2024-07-05T13:38:54.166242Z"},"trusted":true},"outputs":[],"source":["class MovieRecommender:\n","\n","    def __init__(self, num_users, num_movies, num_features, num_movie_features, movieFeatures):\n","        \"\"\"\n","        Initialisation de notre système de recommendation\n","\n","        Paramètres:\n","        -----------\n","        num_user: int\n","            nombre d'utilisateurs dans notre système\n","        num_movies: int\n","            nombre de films\n","        num_features: int\n","            nombre de features du système\n","        num_movie_features: int\n","            nombre de caractèristiques (features type genre, directors etc) des films\n","        movieFeatures: tf.tensor\n","            tensor contenant les caractéristiques (features type genre, directors etc) pour chaque film\n","        \"\"\"\n","        self.num_users = num_users\n","        self.num_movies = num_movies\n","        self.num_features = num_features\n","        self.num_movie_features = num_movie_features\n","        self.movieFeatures = movieFeatures\n","        \n","        tf.random.set_seed(1234)\n","        \n","        self.X = tf.Variable(tf.random.normal((self.num_movies, self.num_features), dtype=tf.float64), name=\"X\")\n","        self.W = tf.Variable(tf.random.normal((self.num_users, self.num_features), dtype=tf.float64), name=\"W\")\n","        self.b = tf.Variable(tf.random.normal((1, self.num_users), dtype=tf.float64), name=\"b\")\n","        self.W_features = tf.Variable(tf.random.normal((self.num_movie_features, self.num_features), dtype=tf.float64), name=\"W_features\")\n","        \n","        self.mean = None\n","        \n","        \n","    def fit(self, Y, mean, r_mask, iterations, lambda_, learning_r):\n","        \"\"\"\n","        Fonction qui entraîne notre système de recommendation\n","        \n","        Paramètres:\n","        -----------\n","        Y: np.ndarray\n","            Le tableau de notes\n","        mean: np.array\n","            Le tableau avec les notes moyennes (pour calculer plus tard les résultats)\n","        r_mask: np.ndarray\n","            Le tableau indiquant si un utilisateur a noté un film.\n","        iterations: int\n","            Le nombre d'itérations à réaliser pour l'entrainement du modèle\n","        lambda_: float\n","            Le paramètre de régularisation\n","        learning_r: float\n","            Le learning_rate pour l'optimizer\n","        \"\"\"\n","        self.mean = mean\n","        \n","        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_r)\n","        for iter in range(iterations):\n","            with tf.GradientTape() as tape:\n","                # Calcule le coût\n","                cost_value = cofi_cost_func_v(self.X, self.W, self.W_features, self.b, Y, r_mask, self.movieFeatures, lambda_)\n","\n","            grads = tape.gradient(cost_value, [self.X, self.W, self.W_features, self.b])\n","\n","            # Effectue une étape de descente de gradient en mettant à jour la valeur des variables pour minimiser la perte.\n","            optimizer.apply_gradients(zip(grads, [self.X, self.W, self.W_features, self.b]))\n","\n","            if iter % 20 == 0:\n","                print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")\n","    \n","    \n","    def getResults(self):\n","        \"\"\"\n","        Fonction qui récupère la matrice de scores\n","        \n","        Retours:\n","        -------\n","        np.ndarray\n","            Notes des utilisateurs pour chaque film\n","        \"\"\"\n","        movie_bias = tf.matmul(self.movieFeatures, self.W_features)\n","        p = np.matmul(self.X.numpy() + movie_bias.numpy(), np.transpose(self.W.numpy())) + self.b.numpy()\n","\n","        # ajout de la moyenne pour obtenir les bonnes valeurs\n","        pm = p + self.mean\n","        \n","        # bloquer les valeurs entre 0 et 5 pour éviter des valeurs trop grandes (possible à cause de l'ajout de la moyenne)\n","        pm = np.clip(pm, 0, 5)\n","        \n","        return pm\n","    \n","\n","    def getMetrics(self, Yval, movieList, printExemples=False):\n","        \"\"\"\n","        Fonction qui récupère l'erreur moyenne des prédictions et la précision des prédictions pour évaluer le modèle\n","        \n","        Paramètres:\n","        ----------\n","        Yval: np.ndarray\n","            Le tableau des notes\n","        movieList: List\n","            La liste contenant les titres de tous les films\n","        printExemples: bool\n","            Variable qui permet de print certaines prédictions et leur véritable valeur\n","        \n","        Retours:\n","        -------\n","        Tuple(Float, Float)\n","            la précision du modèle et la racine carrée de l'erreur quadratique moyenne\n","        \"\"\"\n","        pm = self.getResults()\n","\n","        # Récupération des notes de départ\n","        non_zero_indices = np.nonzero(Yval)\n","        rows, cols = non_zero_indices\n","        \n","        if(printExemples):\n","            for k in range (5):\n","                my_ratings = Yval[:,cols[k]]\n","                my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n","\n","                my_predictions = pm[:, k]\n","\n","                print(\"\\n\\nOriginal vs Predicted ratings for\",(k + 1), \"\\n\")\n","                for i in range(len(my_ratings)):\n","                    if my_ratings[i] > 0:\n","                        print(\n","                            f\"Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}\"\n","                        )\n","\n","        predicted_ratings = pm[rows, cols]\n","        real_ratings = Yval[rows, cols]\n","\n","        # Calcul de la racine carrée de l'erreur quadratique moyenne (RMSE)\n","        # Ce métrique permet de se rendre compte de la capacité de notre modèle à prédire la bonne valeur\n","        # Il est également plus sensible aux grands écarts que la simple erreur absolue moyenne\n","        rmse = np.sqrt(np.mean((predicted_ratings - real_ratings) ** 2))\n","        \n","        # Seuil pour considérer une recommandation comme pertinente\n","        threshold = 4\n","\n","        # Convertir les notes en recommandations pertinentes ou non pertinentes\n","        predicted_pertinent = predicted_ratings >= threshold\n","        real_pertinent = real_ratings >= threshold\n","\n","        # Calcul de la précision (et donc la pertinence des propositions de notre modèle)\n","        precision = precision_score(real_pertinent, predicted_pertinent)\n","        \n","        return precision, rmse\n","        \n","\n","    def getCoupleRatings(self, user_id1, user_id2):\n","        \"\"\"\n","        Fonction qui permet de récupérer les notes données par un couple de personnes\n","        \n","        Paramètres:\n","        -----------\n","        user_id1: int\n","            Le premier utilisateur de notre couple\n","        user_id2: int\n","            Le deuxième utilisateur de notre couple\n","        \n","        Retours:\n","        --------\n","        np.array\n","            L'array contenant la note donnée par notre couple pour chaque film\n","        \"\"\"\n","        pm = self.getResults()\n","        \n","        user_ratings1 = pm[:, user_id1-1]\n","        user_ratings2 = pm[:, user_id2-1]\n","        \n","        # La note d'un couple pour un film correspond à la moyenne de leurs notes respectives\n","        couple_ratings = (user_ratings1 + user_ratings2) / 2\n","\n","        return couple_ratings\n","    \n","\n","    def getMovieRecommendation(self, user_id1, user_id2, movies, R):\n","        \"\"\"\n","        Fonction qui récupère le meilleur film pour un couple d'utilisateurs\n","        \n","        Paramètres:\n","        -----------\n","        user_id1: int\n","            Le premier utilisateur de notre couple\n","        user_id2: int\n","            Le deuxième utilisateur de notre couple\n","        movies: pd.dataframe\n","            Le dataframe contenant tous les films, leurs caractéristiques etc\n","        R: np.ndarray\n","            Le tableau indiquant si un utilisateur a noté un film.\n","            \n","        Retours:\n","        --------\n","        object:\n","            object contenant l'id, le titre et le score du film choisi pour ce couple\n","        \"\"\"\n","        couple_ratings = self.getCoupleRatings(user_id1, user_id2)\n","        \n","        # Récupère les films vu par chaque utilisateur\n","        movies_seen1 = R[:, user_id1-1]\n","        movies_seen2 = R[:, user_id2-1]\n","\n","        couple_scores = []\n","        fallback_scores = []\n","\n","        # Calcule le couple score pour chaque film (la note donnée avec parfois un bonus)\n","        # Elimine les films vu par les 2 utilisateurs\n","        for i in range(len(couple_ratings)):\n","            avg_rating = couple_ratings[i]\n","\n","            if movies_seen1[i] and movies_seen2[i]:\n","                # On garde sous la main ceux notés par les deux au cas où il n'y a aucun nouveau film\n","                fallback_scores.append((i, avg_rating))\n","                continue\n","            elif movies_seen1[i] or movies_seen2[i]:\n","                couple_score = avg_rating\n","            else:\n","                # Les films vu par aucun des deux ont un bonus pour les prioritiser\n","                couple_score = avg_rating + 1\n","\n","            couple_scores.append((i, couple_score))\n","\n","        # Choisi le film avec le meilleur couple_score\n","        if not couple_scores:\n","            best_movie = max(fallback_scores, key=lambda x: x[1])\n","        else:\n","            best_movie = max(couple_scores, key=lambda x: x[1])\n","\n","        best_movie_id = best_movie[0]\n","        best_movie_score = best_movie[1]\n","        best_movie_title = movies.iloc[best_movie_id]['title']\n","\n","        return {\n","            'movie_id': best_movie_id + 1,\n","            'title': best_movie_title,\n","            'couple_score': best_movie_score\n","        }\n","        "]},{"cell_type":"markdown","metadata":{},"source":["# Utilisation du modèle avec Optuna pour trouver les meilleurs hyperparamètres"]},{"cell_type":"markdown","metadata":{},"source":["Nous avons deux options pour optuna:\n","- minimiser le rmse (et donc obenir des notes prédies le plus proche possible de la réelle)\n","- maximiser la précision (et donc s'assurer que les prédictions données soient cohérentes avec ce les utilisateurs trouvent bien)\n","\n","Minimiser les erreurs permettrait d'avoir des notes plus proches de la réalité et donc de pouvoir dans certains cas obtenir une meilleure précision (sauf si les notes sont toujours juste en dessous du seuil). Nous allons donc essayer de minimiser la rmse."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T13:38:54.198072Z","iopub.status.busy":"2024-07-05T13:38:54.197778Z","iopub.status.idle":"2024-07-05T15:14:27.889935Z","shell.execute_reply":"2024-07-05T15:14:27.889083Z","shell.execute_reply.started":"2024-07-05T13:38:54.198047Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:38:54,207] A new study created in memory with name: no-name-ffcaa807-147e-44c3-ba2a-0f9444ea2bae\n"]},{"name":"stdout","output_type":"stream","text":["Training loss at iteration 0: 66544636687.9\n","Training loss at iteration 20: 13596779869.0\n","Training loss at iteration 40: 4182288907.6\n","Training loss at iteration 60: 1830114605.0\n","Training loss at iteration 80: 981811856.0\n","Training loss at iteration 100: 590712622.8\n","Training loss at iteration 120: 382411532.5\n","Training loss at iteration 140: 261228498.3\n","Training loss at iteration 160: 186218594.7\n","Training loss at iteration 180: 137482925.1\n","Training loss at iteration 200: 104526785.0\n","Training loss at iteration 220: 81474591.0\n","Training loss at iteration 240: 64875237.3\n","Training loss at iteration 260: 52618094.7\n","Training loss at iteration 280: 43366515.5\n","Training loss at iteration 300: 36247736.9\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:41:24,642] Trial 0 finished with value: 2.370345652096164 and parameters: {'num_features': 86, 'lambda': 2.504176848173028, 'learning_rate': 0.019326437887489126, 'iterations': 308}. Best is trial 0 with value: 2.370345652096164.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6164383561643836\n","Training loss at iteration 0: 89317740964.6\n","Training loss at iteration 20: 1285896096.2\n","Training loss at iteration 40: 176134399.0\n","Training loss at iteration 60: 41744902.9\n","Training loss at iteration 80: 17700403.1\n","Training loss at iteration 100: 10842998.3\n","Training loss at iteration 120: 7769918.2\n","Training loss at iteration 140: 5977305.4\n","Training loss at iteration 160: 4800593.0\n","Training loss at iteration 180: 3979492.2\n","Training loss at iteration 200: 3383543.7\n","Training loss at iteration 220: 2937637.8\n","Training loss at iteration 240: 2595618.3\n","Training loss at iteration 260: 2327748.5\n","Training loss at iteration 280: 2114219.7\n","Training loss at iteration 300: 1941131.0\n","Training loss at iteration 320: 1799160.4\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:43:59,950] Trial 1 finished with value: 1.945836738564395 and parameters: {'num_features': 117, 'lambda': 1.1733250679702198, 'learning_rate': 0.08744295104090717, 'iterations': 321}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6582278481012658\n","Training loss at iteration 0: 165697623624.1\n","Training loss at iteration 20: 31244510989.9\n","Training loss at iteration 40: 8930745855.3\n","Training loss at iteration 60: 3732298692.9\n","Training loss at iteration 80: 1986695026.0\n","Training loss at iteration 100: 1218848477.2\n","Training loss at iteration 120: 816343548.2\n","Training loss at iteration 140: 580624938.1\n","Training loss at iteration 160: 431830337.3\n","Training loss at iteration 180: 332576345.0\n","Training loss at iteration 200: 263458568.8\n","Training loss at iteration 220: 213625083.4\n","Training loss at iteration 240: 176647200.2\n","Training loss at iteration 260: 148535352.1\n","Training loss at iteration 280: 126716123.9\n","Training loss at iteration 300: 109474340.4\n","Training loss at iteration 320: 95634211.1\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:46:36,184] Trial 2 finished with value: 2.7673108064094083 and parameters: {'num_features': 217, 'lambda': 7.974973901465258, 'learning_rate': 0.016403696369836858, 'iterations': 322}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.5836298932384342\n","Training loss at iteration 0: 49078932613.2\n","Training loss at iteration 20: 43985777984.6\n","Training loss at iteration 40: 39531629505.3\n","Training loss at iteration 60: 35663509507.4\n","Training loss at iteration 80: 32291919683.6\n","Training loss at iteration 100: 29335533424.4\n","Training loss at iteration 120: 26728682975.6\n","Training loss at iteration 140: 24418790383.4\n","Training loss at iteration 160: 22363214248.7\n","Training loss at iteration 180: 20526902825.4\n","Training loss at iteration 200: 18880722207.2\n","Training loss at iteration 220: 17400238831.4\n","Training loss at iteration 240: 16064807799.7\n","Training loss at iteration 260: 14856874102.2\n","Training loss at iteration 280: 13761427075.8\n","Training loss at iteration 300: 12765568204.5\n","Training loss at iteration 320: 11858164582.0\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:49:13,254] Trial 3 finished with value: 2.8782535481133076 and parameters: {'num_features': 64, 'lambda': 3.223954021815951, 'learning_rate': 0.0013161495206794578, 'iterations': 324}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.5860927152317881\n","Training loss at iteration 0: 190278176025.7\n","Training loss at iteration 20: 128343128997.8\n","Training loss at iteration 40: 88778686240.8\n","Training loss at iteration 60: 63292452966.1\n","Training loss at iteration 80: 46333431358.6\n","Training loss at iteration 100: 34659021707.4\n","Training loss at iteration 120: 26397682550.0\n","Training loss at iteration 140: 20424169509.9\n","Training loss at iteration 160: 16029139949.9\n","Training loss at iteration 180: 12747423255.0\n","Training loss at iteration 200: 10264575738.1\n","Training loss at iteration 220: 8363116058.4\n","Training loss at iteration 240: 6889975089.6\n","Training loss at iteration 260: 5735921936.2\n","Training loss at iteration 280: 4822104369.4\n","Training loss at iteration 300: 4091012406.4\n","Training loss at iteration 320: 3500296237.8\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:51:51,294] Trial 4 finished with value: 2.880336623893564 and parameters: {'num_features': 250, 'lambda': 3.137266289720043, 'learning_rate': 0.0035435928857802195, 'iterations': 325}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.5993485342019544\n","Training loss at iteration 0: 131548149956.1\n","Training loss at iteration 20: 5980110738.3\n","Training loss at iteration 40: 1182774760.4\n","Training loss at iteration 60: 421893030.9\n","Training loss at iteration 80: 225163218.6\n","Training loss at iteration 100: 146057489.1\n","Training loss at iteration 120: 103673394.4\n","Training loss at iteration 140: 77619945.3\n","Training loss at iteration 160: 60415616.1\n","Training loss at iteration 180: 48500889.9\n","Training loss at iteration 200: 39939188.8\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:53:36,928] Trial 5 finished with value: 2.6388369021329474 and parameters: {'num_features': 172, 'lambda': 6.096162665440782, 'learning_rate': 0.037788601945641515, 'iterations': 217}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.593103448275862\n","Training loss at iteration 0: 150313018050.8\n","Training loss at iteration 20: 75625750760.4\n","Training loss at iteration 40: 40946422577.4\n","Training loss at iteration 60: 24176932420.5\n","Training loss at iteration 80: 15322149239.3\n","Training loss at iteration 100: 10245337445.3\n","Training loss at iteration 120: 7148642347.0\n","Training loss at iteration 140: 5169070481.6\n","Training loss at iteration 160: 3854253205.8\n","Training loss at iteration 180: 2951543821.5\n","Training loss at iteration 200: 2313242526.3\n","Training loss at iteration 220: 1849833367.7\n","Training loss at iteration 240: 1505356630.5\n","Training loss at iteration 260: 1243837221.2\n","Training loss at iteration 280: 1041541853.0\n","Training loss at iteration 300: 882431563.7\n","Training loss at iteration 320: 755421219.7\n","Training loss at iteration 340: 652688349.5\n","Training loss at iteration 360: 568605942.3\n","Training loss at iteration 380: 499054492.9\n","Training loss at iteration 400: 440969375.5\n","Training loss at iteration 420: 392037186.4\n","Training loss at iteration 440: 350488228.5\n","Training loss at iteration 460: 314952209.3\n","Training loss at iteration 480: 284356266.5\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 13:57:33,949] Trial 6 finished with value: 2.7956195654868865 and parameters: {'num_features': 196, 'lambda': 5.2886533160278795, 'learning_rate': 0.006696909906116753, 'iterations': 486}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.5619047619047619\n","Training loss at iteration 0: 148904344006.0\n","Training loss at iteration 20: 3328231912.3\n","Training loss at iteration 40: 531394355.9\n","Training loss at iteration 60: 147257303.5\n","Training loss at iteration 80: 69929201.9\n","Training loss at iteration 100: 45034726.6\n","Training loss at iteration 120: 32829266.9\n","Training loss at iteration 140: 25361572.3\n","Training loss at iteration 160: 20322398.6\n","Training loss at iteration 180: 16739662.2\n","Training loss at iteration 200: 14100616.8\n","Training loss at iteration 220: 12102596.5\n","Training loss at iteration 240: 10555347.6\n","Training loss at iteration 260: 9334023.8\n","Training loss at iteration 280: 8353914.7\n","Training loss at iteration 300: 7555938.4\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:00:09,210] Trial 7 finished with value: 2.3823703419717397 and parameters: {'num_features': 194, 'lambda': 2.5214125696529197, 'learning_rate': 0.059271884267411236, 'iterations': 315}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6245487364620939\n","Training loss at iteration 0: 108647003977.6\n","Training loss at iteration 20: 2949666495.8\n","Training loss at iteration 40: 516752272.1\n","Training loss at iteration 60: 163459767.5\n","Training loss at iteration 80: 84439628.4\n","Training loss at iteration 100: 55898068.7\n","Training loss at iteration 120: 41058919.0\n","Training loss at iteration 140: 31839893.0\n","Training loss at iteration 160: 25621313.7\n","Training loss at iteration 180: 21221379.2\n","Training loss at iteration 200: 17998121.9\n","Training loss at iteration 220: 15570117.6\n","Training loss at iteration 240: 13697540.4\n","Training loss at iteration 260: 12223746.3\n","Training loss at iteration 280: 11043167.2\n","Training loss at iteration 300: 10082385.5\n","Training loss at iteration 320: 9289710.3\n","Training loss at iteration 340: 8627533.1\n","Training loss at iteration 360: 8067955.4\n","Training loss at iteration 380: 7590346.8\n","Training loss at iteration 400: 7178926.5\n","Training loss at iteration 420: 6821281.3\n","Training loss at iteration 440: 6508062.3\n","Training loss at iteration 460: 6231748.4\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:04:01,441] Trial 8 finished with value: 2.2035781504946006 and parameters: {'num_features': 143, 'lambda': 6.957704962706314, 'learning_rate': 0.0531409562514293, 'iterations': 472}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6484375\n","Training loss at iteration 0: 59942958589.6\n","Training loss at iteration 20: 48960172168.2\n","Training loss at iteration 40: 40348567426.6\n","Training loss at iteration 60: 33634298479.4\n","Training loss at iteration 80: 28334661610.0\n","Training loss at iteration 100: 24087727899.2\n","Training loss at iteration 120: 20637927972.8\n","Training loss at iteration 140: 17802933685.3\n","Training loss at iteration 160: 15449679441.8\n","Training loss at iteration 180: 13479014460.1\n","Training loss at iteration 200: 11815771030.3\n","Training loss at iteration 220: 10402127611.8\n","Training loss at iteration 240: 9193040720.1\n","Training loss at iteration 260: 8153024937.4\n","Training loss at iteration 280: 7253838968.0\n","Training loss at iteration 300: 6472795818.2\n","Training loss at iteration 320: 5791511675.0\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:06:40,045] Trial 9 finished with value: 2.816413700772726 and parameters: {'num_features': 78, 'lambda': 2.8959742087788247, 'learning_rate': 0.002369143799730675, 'iterations': 323}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.572289156626506\n","Training loss at iteration 0: 100893118934.3\n","Training loss at iteration 20: 40580581200.0\n","Training loss at iteration 40: 18711940137.1\n","Training loss at iteration 60: 10028004197.9\n","Training loss at iteration 80: 6002024391.7\n","Training loss at iteration 100: 3874517019.6\n","Training loss at iteration 120: 2642805747.2\n","Training loss at iteration 140: 1882031822.4\n","Training loss at iteration 160: 1388135137.1\n","Training loss at iteration 180: 1054143949.8\n","Training loss at iteration 200: 820379705.9\n","Training loss at iteration 220: 651886379.3\n","Training loss at iteration 240: 527329687.5\n","Training loss at iteration 260: 433213280.5\n","Training loss at iteration 280: 360724971.6\n","Training loss at iteration 300: 303948078.7\n","Training loss at iteration 320: 258810551.2\n","Training loss at iteration 340: 222447553.7\n","Training loss at iteration 360: 192803559.4\n","Training loss at iteration 380: 168377383.9\n","Training loss at iteration 400: 148055102.3\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:10:02,218] Trial 10 finished with value: 2.735495117930671 and parameters: {'num_features': 132, 'lambda': 1.0911988809274409, 'learning_rate': 0.009895954323825082, 'iterations': 413}. Best is trial 1 with value: 1.945836738564395.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.5439739413680782\n","Training loss at iteration 0: 96175424646.4\n","Training loss at iteration 20: 1212820373.9\n","Training loss at iteration 40: 154231791.5\n","Training loss at iteration 60: 33646277.3\n","Training loss at iteration 80: 13319893.6\n","Training loss at iteration 100: 7944578.5\n","Training loss at iteration 120: 5680385.9\n","Training loss at iteration 140: 4394567.2\n","Training loss at iteration 160: 3561485.2\n","Training loss at iteration 180: 2985068.8\n","Training loss at iteration 200: 2569346.7\n","Training loss at iteration 220: 2260253.8\n","Training loss at iteration 240: 2024146.7\n","Training loss at iteration 260: 1839382.3\n","Training loss at iteration 280: 1692828.3\n","Training loss at iteration 300: 1575913.3\n","Training loss at iteration 320: 1477537.0\n","Training loss at iteration 340: 1396409.5\n","Training loss at iteration 360: 1328921.9\n","Training loss at iteration 380: 1271258.0\n","Training loss at iteration 400: 1221546.3\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:13:18,534] Trial 11 finished with value: 1.812684560579625 and parameters: {'num_features': 126, 'lambda': 1.0352710660976583, 'learning_rate': 0.0989881605761945, 'iterations': 403}. Best is trial 11 with value: 1.812684560579625.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6867469879518072\n","Training loss at iteration 0: 84492646710.1\n","Training loss at iteration 20: 1174462305.3\n","Training loss at iteration 40: 160426692.4\n","Training loss at iteration 60: 37392249.9\n","Training loss at iteration 80: 15643761.2\n","Training loss at iteration 100: 9510110.4\n","Training loss at iteration 120: 6791711.3\n","Training loss at iteration 140: 5215512.1\n","Training loss at iteration 160: 4183738.3\n","Training loss at iteration 180: 3465586.5\n","Training loss at iteration 200: 2944716.9\n","Training loss at iteration 220: 2555391.3\n","Training loss at iteration 240: 2257146.9\n","Training loss at iteration 260: 2023793.5\n","Training loss at iteration 280: 1837883.2\n","Training loss at iteration 300: 1687429.9\n","Training loss at iteration 320: 1564051.5\n","Training loss at iteration 340: 1461436.6\n","Training loss at iteration 360: 1376240.1\n","Training loss at iteration 380: 1302370.4\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:16:32,153] Trial 12 finished with value: 1.8877074134743381 and parameters: {'num_features': 110, 'lambda': 1.0074615372771352, 'learning_rate': 0.08896627063206125, 'iterations': 396}. Best is trial 11 with value: 1.812684560579625.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6440677966101694\n","Training loss at iteration 0: 82391530172.8\n","Training loss at iteration 20: 1028881119.8\n","Training loss at iteration 40: 134265532.4\n","Training loss at iteration 60: 29676848.9\n","Training loss at iteration 80: 12040645.7\n","Training loss at iteration 100: 7333965.3\n","Training loss at iteration 120: 5337156.1\n","Training loss at iteration 140: 4199583.4\n","Training loss at iteration 160: 3458691.6\n","Training loss at iteration 180: 2943332.3\n","Training loss at iteration 200: 2569654.7\n","Training loss at iteration 220: 2289997.3\n","Training loss at iteration 240: 2075223.6\n","Training loss at iteration 260: 1906616.5\n","Training loss at iteration 280: 1774719.7\n","Training loss at iteration 300: 1662735.4\n","Training loss at iteration 320: 1571402.8\n","Training loss at iteration 340: 1495369.4\n","Training loss at iteration 360: 1431061.3\n","Training loss at iteration 380: 1375985.3\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:19:47,773] Trial 13 finished with value: 1.6804495925596226 and parameters: {'num_features': 107, 'lambda': 1.597176647007939, 'learning_rate': 0.09947619174632374, 'iterations': 399}. Best is trial 13 with value: 1.6804495925596226.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6907630522088354\n","Training loss at iteration 0: 77729238434.2\n","Training loss at iteration 20: 5959744525.5\n","Training loss at iteration 40: 1270292881.5\n","Training loss at iteration 60: 481504442.1\n","Training loss at iteration 80: 252552996.1\n","Training loss at iteration 100: 155605308.4\n","Training loss at iteration 120: 104400537.9\n","Training loss at iteration 140: 74036311.5\n","Training loss at iteration 160: 54736121.5\n","Training loss at iteration 180: 41839261.2\n","Training loss at iteration 200: 32871300.5\n","Training loss at iteration 220: 26426092.3\n","Training loss at iteration 240: 21663035.1\n","Training loss at iteration 260: 18058288.2\n","Training loss at iteration 280: 15273610.0\n","Training loss at iteration 300: 13083748.8\n","Training loss at iteration 320: 11334578.9\n","Training loss at iteration 340: 9918082.9\n","Training loss at iteration 360: 8756927.7\n","Training loss at iteration 380: 7794682.5\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:23:02,125] Trial 14 finished with value: 2.2445600551966174 and parameters: {'num_features': 101, 'lambda': 1.587111818929673, 'learning_rate': 0.03266128813506649, 'iterations': 397}. Best is trial 13 with value: 1.6804495925596226.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6567164179104478\n","Training loss at iteration 0: 39738856463.9\n","Training loss at iteration 20: 466642933.2\n","Training loss at iteration 40: 66511114.1\n","Training loss at iteration 60: 14723587.6\n","Training loss at iteration 80: 5893748.2\n","Training loss at iteration 100: 3561811.0\n","Training loss at iteration 120: 2589403.1\n","Training loss at iteration 140: 2047646.6\n","Training loss at iteration 160: 1701846.7\n","Training loss at iteration 180: 1465218.3\n","Training loss at iteration 200: 1295856.4\n","Training loss at iteration 220: 1170428.2\n","Training loss at iteration 240: 1074900.2\n","Training loss at iteration 260: 1000396.5\n","Training loss at iteration 280: 941084.6\n","Training loss at iteration 300: 893009.6\n","Training loss at iteration 320: 853416.1\n","Training loss at iteration 340: 820339.7\n","Training loss at iteration 360: 792350.2\n","Training loss at iteration 380: 768387.7\n","Training loss at iteration 400: 747653.4\n","Training loss at iteration 420: 729536.8\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:26:36,461] Trial 15 finished with value: 1.2912629249811782 and parameters: {'num_features': 52, 'lambda': 1.5200780975136425, 'learning_rate': 0.09724992292230974, 'iterations': 439}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.7230769230769231\n","Training loss at iteration 0: 45550042393.9\n","Training loss at iteration 20: 6831433479.2\n","Training loss at iteration 40: 1804678685.6\n","Training loss at iteration 60: 732436689.0\n","Training loss at iteration 80: 373283793.1\n","Training loss at iteration 100: 214878495.2\n","Training loss at iteration 120: 133506066.6\n","Training loss at iteration 140: 87806581.2\n","Training loss at iteration 160: 60492360.6\n","Training loss at iteration 180: 43336549.7\n","Training loss at iteration 200: 32100654.5\n","Training loss at iteration 220: 24471442.6\n","Training loss at iteration 240: 19125696.6\n","Training loss at iteration 260: 15275359.9\n","Training loss at iteration 280: 12434155.8\n","Training loss at iteration 300: 10292393.0\n","Training loss at iteration 320: 8647161.2\n","Training loss at iteration 340: 7362058.5\n","Training loss at iteration 360: 6343233.6\n","Training loss at iteration 380: 5524731.8\n","Training loss at iteration 400: 4859303.4\n","Training loss at iteration 420: 4312500.7\n","Training loss at iteration 440: 3858805.7\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:30:16,949] Trial 16 finished with value: 1.9235185311427363 and parameters: {'num_features': 59, 'lambda': 1.7458884258250134, 'learning_rate': 0.02496453967290708, 'iterations': 449}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.65\n","Training loss at iteration 0: 38960125689.5\n","Training loss at iteration 20: 1384696672.9\n","Training loss at iteration 40: 233677462.8\n","Training loss at iteration 60: 73624103.6\n","Training loss at iteration 80: 35309434.0\n","Training loss at iteration 100: 21058098.1\n","Training loss at iteration 120: 13953373.8\n","Training loss at iteration 140: 9849174.6\n","Training loss at iteration 160: 7286579.2\n","Training loss at iteration 180: 5601662.4\n","Training loss at iteration 200: 4448148.9\n","Training loss at iteration 220: 3631413.0\n","Training loss at iteration 240: 3036321.6\n","Training loss at iteration 260: 2591905.6\n","Training loss at iteration 280: 2252845.7\n","Training loss at iteration 300: 1989289.5\n","Training loss at iteration 320: 1781025.9\n","Training loss at iteration 340: 1614035.8\n","Training loss at iteration 360: 1478379.4\n","Training loss at iteration 380: 1366872.9\n","Training loss at iteration 400: 1274233.4\n","Training loss at iteration 420: 1196515.3\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:33:51,286] Trial 17 finished with value: 1.6564426675000594 and parameters: {'num_features': 51, 'lambda': 1.7414614269088684, 'learning_rate': 0.050173184581898025, 'iterations': 436}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6912442396313364\n","Training loss at iteration 0: 47453736321.3\n","Training loss at iteration 20: 1725536508.2\n","Training loss at iteration 40: 298259135.6\n","Training loss at iteration 60: 96406490.4\n","Training loss at iteration 80: 47324302.3\n","Training loss at iteration 100: 28718176.9\n","Training loss at iteration 120: 19275793.7\n","Training loss at iteration 140: 13733386.1\n","Training loss at iteration 160: 10224012.4\n","Training loss at iteration 180: 7888241.8\n","Training loss at iteration 200: 6272272.4\n","Training loss at iteration 220: 5117797.5\n","Training loss at iteration 240: 4270159.6\n","Training loss at iteration 260: 3632967.7\n","Training loss at iteration 280: 3144058.4\n","Training loss at iteration 300: 2762127.2\n","Training loss at iteration 320: 2458996.1\n","Training loss at iteration 340: 2214987.6\n","Training loss at iteration 360: 2016070.7\n","Training loss at iteration 380: 1852052.2\n","Training loss at iteration 400: 1715402.2\n","Training loss at iteration 420: 1600472.9\n","Training loss at iteration 440: 1502969.7\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:37:28,070] Trial 18 finished with value: 1.759913179290191 and parameters: {'num_features': 62, 'lambda': 2.00932645887218, 'learning_rate': 0.04928832202954881, 'iterations': 442}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6595744680851063\n","Training loss at iteration 0: 38960792864.6\n","Training loss at iteration 20: 13026558791.4\n","Training loss at iteration 40: 5334426716.3\n","Training loss at iteration 60: 2679895169.7\n","Training loss at iteration 80: 1530588113.8\n","Training loss at iteration 100: 941048026.5\n","Training loss at iteration 120: 606939183.7\n","Training loss at iteration 140: 406095149.2\n","Training loss at iteration 160: 280361922.6\n","Training loss at iteration 180: 199058264.7\n","Training loss at iteration 200: 144982580.2\n","Training loss at iteration 220: 108089336.3\n","Training loss at iteration 240: 82324433.4\n","Training loss at iteration 260: 63939864.7\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:39:38,710] Trial 19 finished with value: 2.4992568867511085 and parameters: {'num_features': 51, 'lambda': 4.030329962379433, 'learning_rate': 0.014108080333642253, 'iterations': 266}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.5770609318996416\n","Training loss at iteration 0: 61658380024.3\n","Training loss at iteration 20: 32260558385.4\n","Training loss at iteration 40: 18270561099.1\n","Training loss at iteration 60: 11297638989.9\n","Training loss at iteration 80: 7474034843.9\n","Training loss at iteration 100: 5182776548.6\n","Training loss at iteration 120: 3717435909.1\n","Training loss at iteration 140: 2736559927.7\n","Training loss at iteration 160: 2057888364.0\n","Training loss at iteration 180: 1576177313.0\n","Training loss at iteration 200: 1227033691.0\n","Training loss at iteration 220: 969365891.3\n","Training loss at iteration 240: 776119661.5\n","Training loss at iteration 260: 629046248.4\n","Training loss at iteration 280: 515590590.6\n","Training loss at iteration 300: 426966789.2\n","Training loss at iteration 320: 356932303.4\n","Training loss at iteration 340: 300989187.4\n","Training loss at iteration 360: 255853863.6\n","Training loss at iteration 380: 219099526.3\n","Training loss at iteration 400: 188911540.6\n","Training loss at iteration 420: 163917952.6\n","Training loss at iteration 440: 143070611.3\n","Training loss at iteration 460: 125560820.6\n","Training loss at iteration 480: 110758821.9\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:43:41,489] Trial 20 finished with value: 2.4738851676853866 and parameters: {'num_features': 80, 'lambda': 1.383333536439871, 'learning_rate': 0.007641377107509174, 'iterations': 497}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6193548387096774\n","Training loss at iteration 0: 71925742151.4\n","Training loss at iteration 20: 1537616016.2\n","Training loss at iteration 40: 248411823.4\n","Training loss at iteration 60: 71273426.0\n","Training loss at iteration 80: 34233735.1\n","Training loss at iteration 100: 21724113.0\n","Training loss at iteration 120: 15518463.4\n","Training loss at iteration 140: 11757044.0\n","Training loss at iteration 160: 9257121.1\n","Training loss at iteration 180: 7507720.4\n","Training loss at iteration 200: 6238759.0\n","Training loss at iteration 220: 5291909.2\n","Training loss at iteration 240: 4568627.2\n","Training loss at iteration 260: 4004951.8\n","Training loss at iteration 280: 3557959.5\n","Training loss at iteration 300: 3198059.1\n","Training loss at iteration 320: 2904336.6\n","Training loss at iteration 340: 2661708.6\n","Training loss at iteration 360: 2459093.5\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:46:46,274] Trial 21 finished with value: 1.9449988844046961 and parameters: {'num_features': 94, 'lambda': 1.9892361580228048, 'learning_rate': 0.06326326824743499, 'iterations': 376}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.668\n","Training loss at iteration 0: 38609780830.8\n","Training loss at iteration 20: 3164472206.9\n","Training loss at iteration 40: 651891714.6\n","Training loss at iteration 60: 235398101.8\n","Training loss at iteration 80: 114571455.4\n","Training loss at iteration 100: 65192210.1\n","Training loss at iteration 120: 40611852.1\n","Training loss at iteration 140: 26971581.8\n","Training loss at iteration 160: 18845828.4\n","Training loss at iteration 180: 13733648.3\n","Training loss at iteration 200: 10368623.9\n","Training loss at iteration 220: 8066939.7\n","Training loss at iteration 240: 6440022.6\n","Training loss at iteration 260: 5257178.8\n","Training loss at iteration 280: 4376048.3\n","Training loss at iteration 300: 3705708.5\n","Training loss at iteration 320: 3186284.1\n","Training loss at iteration 340: 2777256.4\n","Training loss at iteration 360: 2450533.6\n","Training loss at iteration 380: 2186215.0\n","Training loss at iteration 400: 1969928.9\n","Training loss at iteration 420: 1791115.9\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:50:20,536] Trial 22 finished with value: 1.6219073863018552 and parameters: {'num_features': 50, 'lambda': 1.3260048518626708, 'learning_rate': 0.03477102015434818, 'iterations': 436}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6624472573839663\n","Training loss at iteration 0: 38609783259.0\n","Training loss at iteration 20: 3400443949.8\n","Training loss at iteration 40: 717871093.6\n","Training loss at iteration 60: 262096961.6\n","Training loss at iteration 80: 127789376.7\n","Training loss at iteration 100: 72512067.9\n","Training loss at iteration 120: 44993217.1\n","Training loss at iteration 140: 29760742.6\n","Training loss at iteration 160: 20714533.9\n","Training loss at iteration 180: 15040563.7\n","Training loss at iteration 200: 11316333.2\n","Training loss at iteration 220: 8775557.6\n","Training loss at iteration 240: 6983849.0\n","Training loss at iteration 260: 5683922.7\n","Training loss at iteration 280: 4717376.1\n","Training loss at iteration 300: 3983267.4\n","Training loss at iteration 320: 3415264.7\n","Training loss at iteration 340: 2968569.9\n","Training loss at iteration 360: 2612180.8\n","Training loss at iteration 380: 2324171.7\n","Training loss at iteration 400: 2088732.1\n","Training loss at iteration 420: 1894261.1\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:53:55,425] Trial 23 finished with value: 1.6311620242441285 and parameters: {'num_features': 50, 'lambda': 1.3344995822219627, 'learning_rate': 0.033603035607519004, 'iterations': 439}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6610878661087866\n","Training loss at iteration 0: 55766845504.8\n","Training loss at iteration 20: 5817750881.8\n","Training loss at iteration 40: 1328026562.4\n","Training loss at iteration 60: 509928472.8\n","Training loss at iteration 80: 259476575.2\n","Training loss at iteration 100: 152906794.3\n","Training loss at iteration 120: 98109324.2\n","Training loss at iteration 140: 66788036.3\n","Training loss at iteration 160: 47604555.5\n","Training loss at iteration 180: 35222661.4\n","Training loss at iteration 200: 26881844.1\n","Training loss at iteration 220: 21058276.4\n","Training loss at iteration 240: 16866659.8\n","Training loss at iteration 260: 13770010.8\n","Training loss at iteration 280: 11430242.8\n","Training loss at iteration 300: 9627434.6\n","Training loss at iteration 320: 8214359.3\n","Training loss at iteration 340: 7089908.0\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 14:56:50,352] Trial 24 finished with value: 2.1150777881962766 and parameters: {'num_features': 73, 'lambda': 1.3109517739677263, 'learning_rate': 0.029489436976882423, 'iterations': 358}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6245487364620939\n","Training loss at iteration 0: 121747553929.5\n","Training loss at iteration 20: 14454676196.4\n","Training loss at iteration 40: 3521127559.7\n","Training loss at iteration 60: 1416426811.1\n","Training loss at iteration 80: 756702361.7\n","Training loss at iteration 100: 469348888.8\n","Training loss at iteration 120: 316889422.4\n","Training loss at iteration 140: 226412218.7\n","Training loss at iteration 160: 168740434.9\n","Training loss at iteration 180: 130008313.5\n","Training loss at iteration 200: 102902291.2\n","Training loss at iteration 220: 83282114.7\n","Training loss at iteration 240: 68674418.6\n","Training loss at iteration 260: 57535439.5\n","Training loss at iteration 280: 48865414.4\n","Training loss at iteration 300: 41996085.8\n","Training loss at iteration 320: 36468271.8\n","Training loss at iteration 340: 31958848.8\n","Training loss at iteration 360: 28235455.4\n","Training loss at iteration 380: 25127812.9\n","Training loss at iteration 400: 22508909.5\n","Training loss at iteration 420: 20282703.5\n","Training loss at iteration 440: 18375398.4\n","Training loss at iteration 460: 16729628.5\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 15:00:40,746] Trial 25 finished with value: 2.4232970075036455 and parameters: {'num_features': 159, 'lambda': 1.3646400008770734, 'learning_rate': 0.02358354828086941, 'iterations': 466}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6192052980132451\n","Training loss at iteration 0: 54261218273.7\n","Training loss at iteration 20: 2779972932.5\n","Training loss at iteration 40: 525912379.9\n","Training loss at iteration 60: 183423390.1\n","Training loss at iteration 80: 92607311.9\n","Training loss at iteration 100: 56146282.9\n","Training loss at iteration 120: 37298771.8\n","Training loss at iteration 140: 26245813.4\n","Training loss at iteration 160: 19288283.3\n","Training loss at iteration 180: 14685900.2\n","Training loss at iteration 200: 11518524.3\n","Training loss at iteration 220: 9265278.2\n","Training loss at iteration 240: 7616434.6\n","Training loss at iteration 260: 6380253.8\n","Training loss at iteration 280: 5433793.1\n","Training loss at iteration 300: 4695765.0\n","Training loss at iteration 320: 4110940.4\n","Training loss at iteration 340: 3640876.4\n","Training loss at iteration 360: 3258233.0\n","Training loss at iteration 380: 2943189.2\n","Training loss at iteration 400: 2681125.7\n","Training loss at iteration 420: 2461091.6\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 15:04:10,277] Trial 26 finished with value: 1.884517072276632 and parameters: {'num_features': 71, 'lambda': 1.9482354392883168, 'learning_rate': 0.041554374591296954, 'iterations': 428}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.659919028340081\n","Training loss at iteration 0: 68085914989.9\n","Training loss at iteration 20: 24633596465.2\n","Training loss at iteration 40: 10613038182.9\n","Training loss at iteration 60: 5487615979.3\n","Training loss at iteration 80: 3212000008.4\n","Training loss at iteration 100: 2032767969.4\n","Training loss at iteration 120: 1357960707.3\n","Training loss at iteration 140: 945862085.3\n","Training loss at iteration 160: 681882483.5\n","Training loss at iteration 180: 506123828.7\n","Training loss at iteration 200: 385197173.4\n","Training loss at iteration 220: 299591179.7\n","Training loss at iteration 240: 237457282.8\n","Training loss at iteration 260: 191356944.2\n","Training loss at iteration 280: 156480283.9\n","Training loss at iteration 300: 129633775.9\n","Training loss at iteration 320: 108646045.2\n","Training loss at iteration 340: 92008727.0\n","Training loss at iteration 360: 78653530.8\n","Training loss at iteration 380: 67810441.7\n","Training loss at iteration 400: 58915496.6\n","Training loss at iteration 420: 51549568.5\n","Training loss at iteration 440: 45396969.1\n","Training loss at iteration 460: 40216971.0\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 15:07:58,573] Trial 27 finished with value: 2.5261092216847882 and parameters: {'num_features': 89, 'lambda': 2.295666449212254, 'learning_rate': 0.012068746664455478, 'iterations': 464}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6014234875444839\n","Training loss at iteration 0: 38612235355.6\n","Training loss at iteration 20: 26891456381.4\n","Training loss at iteration 40: 19243031962.5\n","Training loss at iteration 60: 14230141065.7\n","Training loss at iteration 80: 10827408752.3\n","Training loss at iteration 100: 8426604561.3\n","Training loss at iteration 120: 6675844908.0\n","Training loss at iteration 140: 5364326773.4\n","Training loss at iteration 160: 4360043071.1\n","Training loss at iteration 180: 3577024150.2\n","Training loss at iteration 200: 2957396370.6\n","Training loss at iteration 220: 2461061371.3\n","Training loss at iteration 240: 2059506334.4\n","Training loss at iteration 260: 1731968690.6\n","Training loss at iteration 280: 1462997879.9\n","Training loss at iteration 300: 1240871227.1\n","Training loss at iteration 320: 1056543379.9\n","Training loss at iteration 340: 902934709.7\n","Training loss at iteration 360: 774438486.0\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 15:11:00,485] Trial 28 finished with value: 2.677864180627297 and parameters: {'num_features': 50, 'lambda': 9.913061881064628, 'learning_rate': 0.004535356239760774, 'iterations': 373}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.5784313725490197\n","Training loss at iteration 0: 67215373404.1\n","Training loss at iteration 20: 13343386632.1\n","Training loss at iteration 40: 4035960824.2\n","Training loss at iteration 60: 1755863079.5\n","Training loss at iteration 80: 942315186.7\n","Training loss at iteration 100: 568464708.1\n","Training loss at iteration 120: 369342753.1\n","Training loss at iteration 140: 253285726.2\n","Training loss at iteration 160: 181238274.4\n","Training loss at iteration 180: 134259946.9\n","Training loss at iteration 200: 102368797.0\n","Training loss at iteration 220: 79974602.5\n","Training loss at iteration 240: 63789429.2\n","Training loss at iteration 260: 51797732.4\n","Training loss at iteration 280: 42719152.6\n","Training loss at iteration 300: 35714761.6\n","Training loss at iteration 320: 30219720.1\n","Training loss at iteration 340: 25844461.2\n","Training loss at iteration 360: 22314464.7\n","Training loss at iteration 380: 19432508.1\n","Training loss at iteration 400: 17054407.2\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-07-05 15:14:26,724] Trial 29 finished with value: 2.3919656494948973 and parameters: {'num_features': 88, 'lambda': 1.253498834583448, 'learning_rate': 0.019635238304385672, 'iterations': 420}. Best is trial 15 with value: 1.2912629249811782.\n"]},{"name":"stdout","output_type":"stream","text":["Précision du modèle:  0.6107142857142858\n","Meilleurs hyperparamètres trouvés:  {'num_features': 52, 'lambda': 1.5200780975136425, 'learning_rate': 0.09724992292230974, 'iterations': 439}\n","Meilleure RMSE sur le set de validation:  1.2912629249811782\n"]},{"data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>                            <div id=\"6292b62e-1d99-4f19-be45-48ed74efc225\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6292b62e-1d99-4f19-be45-48ed74efc225\")) {                    Plotly.newPlot(                        \"6292b62e-1d99-4f19-be45-48ed74efc225\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"iterations (IntDistribution): 0.07534835015248656\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"num_features (IntDistribution): 0.14233226025204807\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"lambda (FloatDistribution): 0.18048558178642776\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.6018338078090377\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.08\",\"0.14\",\"0.18\",\"0.60\"],\"textposition\":\"outside\",\"x\":[0.07534835015248656,0.14233226025204807,0.18048558178642776,0.6018338078090377],\"y\":[\"iterations\",\"num_features\",\"lambda\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('6292b62e-1d99-4f19-be45-48ed74efc225');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["def objective(trial):\n","    # Définition des hyperparamètres à optimiser\n","    # Les valeurs bornes ont été trouvées après plusieurs essais avec optuna\n","    num_features = trial.suggest_int('num_features', 50, 250)\n","    lambda_ = trial.suggest_float('lambda', 1e0, 1e1, log=True)\n","    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n","    iterations = trial.suggest_int('iterations', 200, 500)\n","\n","    # Création et entraînement du modèle\n","    # Utilisation de R * (Y_train > 0) pour séparer totalement le train set du reste et ne prendre en compte\n","    # que les films notés du train set\n","    recommender = MovieRecommender(num_users, num_movies, num_features, num_movie_features, movie_features)\n","    recommender.fit(Ynorm, Ymean, R * (Y_train > 0), iterations, lambda_, learning_rate)\n","\n","    # Évaluation du modèle sur le set de validation\n","    precision, rmse = recommender.getMetrics(Y_val, movieList)\n","    \n","    print(\"Précision du modèle: \", precision)\n","    \n","    return rmse\n","\n","# Création d'une étude Optuna\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=30)\n","\n","best_params = study.best_params\n","\n","# Affichage des meilleurs résultats\n","print(\"Meilleurs hyperparamètres trouvés: \", best_params)\n","print(\"Meilleure RMSE sur le set de validation: \", study.best_value)\n","\n","# Visualisation de l'importance des hyperparamètres\n","optuna.visualization.plot_param_importances(study)"]},{"cell_type":"markdown","metadata":{},"source":["# Résultats"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T15:14:27.891393Z","iopub.status.busy":"2024-07-05T15:14:27.891053Z","iopub.status.idle":"2024-07-05T15:18:02.399163Z","shell.execute_reply":"2024-07-05T15:18:02.398123Z","shell.execute_reply.started":"2024-07-05T15:14:27.891360Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training loss at iteration 0: 39738856463.9\n","Training loss at iteration 20: 466642933.2\n","Training loss at iteration 40: 66511114.1\n","Training loss at iteration 60: 14723587.6\n","Training loss at iteration 80: 5893748.2\n","Training loss at iteration 100: 3561811.0\n","Training loss at iteration 120: 2589403.1\n","Training loss at iteration 140: 2047646.6\n","Training loss at iteration 160: 1701846.7\n","Training loss at iteration 180: 1465218.3\n","Training loss at iteration 200: 1295856.4\n","Training loss at iteration 220: 1170428.2\n","Training loss at iteration 240: 1074900.2\n","Training loss at iteration 260: 1000396.5\n","Training loss at iteration 280: 941084.6\n","Training loss at iteration 300: 893009.6\n","Training loss at iteration 320: 853416.1\n","Training loss at iteration 340: 820339.7\n","Training loss at iteration 360: 792350.2\n","Training loss at iteration 380: 768387.7\n","Training loss at iteration 400: 747653.4\n","Training loss at iteration 420: 729536.8\n","\n","\n","Précision sur val set : 0.7230769230769231\n","\n","\n","RMSE sur val set : 1.2912629249811782\n","\n","\n","Précision sur test set : 0.7669902912621359\n","\n","\n","RMSE sur test set : 1.3218356370993276\n"]}],"source":["# Utilisation des meilleurs paramètres pour entrainer notre modèle\n","recommender_final = MovieRecommender(num_users, num_movies, best_params['num_features'], num_movie_features, movie_features)\n","recommender_final.fit(Ynorm, Ymean, R * (Y_train >0), best_params['iterations'], best_params['lambda'], best_params['learning_rate'])\n","\n","# Obtention de l'erreur moyenne de notre modèle sur le validation set et le test set pour visualiser ses performances\n","precision_val, rmse_val = recommender_final.getMetrics(Y_val, movieList)\n","precision_test, rmse_test = recommender_final.getMetrics(Y_test, movieList)\n","\n","print(f\"\\n\\nPrécision sur val set : {precision_val}\")\n","print(f\"\\nRMSE sur val set : {rmse_val}\")\n","print(f\"\\n\\nPrécision sur test set : {precision_test}\")\n","print(f\"\\nRMSE sur test set : {rmse_test}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T15:18:02.400632Z","iopub.status.busy":"2024-07-05T15:18:02.400290Z","iopub.status.idle":"2024-07-05T15:18:02.719929Z","shell.execute_reply":"2024-07-05T15:18:02.719002Z","shell.execute_reply.started":"2024-07-05T15:18:02.400606Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'movie_id': 13, 'title': 'Balto', 'couple_score': 6.0}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#Recommendation pour les utilisateurs 1 et 2\n","best_movie = recommender_final.getMovieRecommendation(1,2, df_movies, R)\n","best_movie"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5306058,"sourceId":8819972,"sourceType":"datasetVersion"},{"datasetId":5326782,"sourceId":8849594,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
